{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the State Farm image data\n",
    "\n",
    "This notebook provides analysis of the provided State Farm data, using Theano and Keras to build the NN.\n",
    "\n",
    "### Prerequisites\n",
    "Please see the Readme.md file for pre-requisite Python libraries\n",
    "\n",
    "Note that the data is available from Kaggle here:  \n",
    "https://www.kaggle.com/c/state-farm-distracted-driver-detection/data\n",
    "\n",
    "Please extract the data set into the /imgs folder within this code.  For example ./state-farm/imgs/ \n",
    "\n",
    "If this is the 1st run after downloading the data, then please set create_repository to True below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "First, let's import what we need and set up environment variables, etc.\n",
    "\n",
    "If the following commands error with the message \"Exception: Can't change the value of this config parameter after initialization!\" then please re-start ipython with the following command:\n",
    "\n",
    "THEANO_FLAGS=device=gpu,floatX=float32 ipython notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 750M (CNMeM is disabled, cuDNN 5005)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Can't change the value of this config parameter after initialization!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e246e7cb99d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/configparser.pyc\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, cls, val)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_override\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             raise Exception(\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0;34m\"Can't change the value of this config parameter \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \"after initialization!\")\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# print \"SETTING PARAM\", self.fullname,(cls), val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Can't change the value of this config parameter after initialization!"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "theano.config.device = 'gpu'\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports of the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# These are the locations of the images provided by Kaggle\n",
    "# Root Dir is needed for Python, but not for create lmdb shell script later... (we need it there too!)\n",
    "image_root_dir = './imgs/'\n",
    "train_image_source_dir = \"./train/\"\n",
    "test_image_source_dir = \"./test/\"\n",
    "driver_image_list = \"./driver_imgs_list.csv\"\n",
    "\n",
    "# These are the locations of the images that we will work with \n",
    "# Note that as we're continually mix up training and validation drivers/images, \n",
    "# then we will store images in one directory and use code to determine whether to train or validate\n",
    "train_images_dir = \"./images/train/\"\n",
    "#validation_images_dir = \"./images/validate/\" \n",
    "test_images_dir = \"./images/test/\"\n",
    "\n",
    "# Some more controls\n",
    "# color type: 1 - grey, 3 - rgb\n",
    "color_type = 1 \n",
    "image_width = 224 \n",
    "image_height = 224 \n",
    "\n",
    "create_repository = False    # True forces pre-processing images, set to True for the first run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start by pre-processing the images\n",
    "There are only 27 different drivers so in order to avoid overfitting, or testing using very similar data to training, we will split the data based on the driver into train and validation sets.\n",
    "\n",
    "Initially though, let's get the list of drivers, see how many images are available for each driver, and which classification they have been labelled with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data summary: \n",
      "  subject classname            img\n",
      "0    p002        c0  img_44733.jpg\n",
      "1    p002        c0  img_72999.jpg\n",
      "2    p002        c0  img_25094.jpg\n",
      "3    p002        c0  img_69092.jpg\n",
      "4    p002        c0  img_92629.jpg\n",
      "\n",
      "Testing data summary: \n",
      "['img_1.jpg', 'img_10.jpg', 'img_100.jpg', 'img_1000.jpg', 'img_100000.jpg', 'img_100001.jpg', 'img_100002.jpg', 'img_100003.jpg', 'img_100004.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Training set is in the provided csv file\n",
    "driver_list = pd.read_csv(driver_image_list)\n",
    "print \"Training data summary: \\n{}\".format(driver_list.head())\n",
    "\n",
    "test_image_list = os.listdir(image_root_dir + test_image_source_dir)\n",
    "print \"\\nTesting data summary: \\n{}\".format(test_image_list[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process images so that they are in an format more suited to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training images found 22424\n"
     ]
    }
   ],
   "source": [
    "def get_driver_images_and_classes(driver_list):\n",
    "    image_list = []\n",
    "    class_list = []\n",
    "    total = 0\n",
    "    for driver_row in [ drvr for drvr in driver_list.iterrows() ]:   # if drvr[1]['subject'] in filter \n",
    "        driver = driver_row[1]  # Drop the index created by the Pandas Dataframe\n",
    "        driver_class = int(driver['classname'][1:])  # Get integer to represent class (eg 'c0' is class '0')\n",
    "        image_list.append(driver['img'])\n",
    "        class_list.append(driver_class)\n",
    "        total += 1\n",
    "    print \"Total number of training images found {}\".format(total)\n",
    "    #Return a list of images and their classification\n",
    "    return np.array(image_list), np.array(class_list)\n",
    "\n",
    "# Create a training list of images and classes from the training set\n",
    "images, classes = get_driver_images_and_classes(driver_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Process the image, for now this is resize only\n",
    "# We'll handle colour/greyscale when we load as cv2 does this for us\n",
    "# TODO - Move directory creation to Python code to be OS independent\n",
    "\n",
    "def pre_process_image(image):\n",
    "    processed_img = cv2.resize(image, (image_width, image_height)) \n",
    "    return processed_img\n",
    "    \n",
    "def create_train_image_repository(images_dest_dir, images_list, class_list, color_type=1):\n",
    "    print \"create_image_repository(): Processing images into {}\".format(images_dest_dir)\n",
    "    copied = 0 \n",
    "    for f, c in zip(images_list, class_list):\n",
    "        dest_dir = images_dest_dir + str(c) + \"/\"\n",
    "        if os.path.exists(dest_dir) == False:\n",
    "            !mkdir $dest_dir\n",
    "        image_filename = image_root_dir + train_image_source_dir + '/c' + str(c) + '/' + f\n",
    "        if color_type == 1:\n",
    "            orig_img = cv2.imread(image_filename, 0)\n",
    "        elif color_type == 3:\n",
    "            orig_img = cv2.imread(image_filename)\n",
    "        processed_image = pre_process_image(orig_img)\n",
    "        cv2.imwrite(images_dest_dir + str(c) + \"/\" + f, processed_image)\n",
    "        copied += 1\n",
    "        if copied % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nCopied {} images...Done!\".format(copied)\n",
    "    return copied\n",
    "\n",
    "def create_test_image_repository(dest_dir, images_list, color_type=1):\n",
    "    print \"create_image_repository(): Processing images into {}\".format(dest_dir)\n",
    "    copied = 0 \n",
    "    for f in images_list:\n",
    "        if os.path.exists(dest_dir) == False:\n",
    "            !mkdir $dest_dir\n",
    "        image_filename = image_root_dir + test_image_source_dir + f\n",
    "        if color_type == 1:\n",
    "            orig_img = cv2.imread(image_filename, 0)\n",
    "        elif color_type == 3:\n",
    "            orig_img = cv2.imread(image_filename)\n",
    "        processed_image = pre_process_image(orig_img)\n",
    "        cv2.imwrite(dest_dir + f, processed_image)\n",
    "        copied += 1\n",
    "        if copied % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nCopied {} images...Done!\".format(copied)\n",
    "    return copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process images if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start by clearing out any old data (ignore failures here if the directory doesn't exist)\n",
    "# TODO - Move to Python code to be OS independent\n",
    "\n",
    "if create_repository:\n",
    "    print \"Deleting old repositories if they exist, this may take a while...\"\n",
    "    !rm -rf $train_images_dir\n",
    "    #!rm -rf $validation_images_dir\n",
    "    !rm -rf $test_images_dir\n",
    "\n",
    "    # Create directories\n",
    "    !mkdir -p $train_images_dir\n",
    "    #!mkdir -p $validation_images_dir\n",
    "    !mkdir -p $test_images_dir\n",
    "\n",
    "    create_test_image_repository(test_images_dir, test_image_list, color_type=color_type)\n",
    "    create_train_image_repository(train_images_dir, images, classes, color_type=color_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Currently unused\n",
    "def render_image(image_filename):\n",
    "    print \"render_image(): Rendering {}\".format(image_filename)\n",
    "    image = cv2.imread(image_filename, color_type_global)\n",
    "    plt.axis(\"off\")\n",
    "    #plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.imshow(image)\n",
    "    plt.show() \n",
    "    #print image.shape\n",
    "    #plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, validation and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the drivers into a training and validation set.  To ensure we don't have overfitting (the training set and the validation set contain the same or similar images) we will split on drivers, so a driver can only appear in training or validation but not both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 drivers: ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n"
     ]
    }
   ],
   "source": [
    "driver_ids = []\n",
    "for id, driver in driver_list.iterrows():\n",
    "    if driver['subject'] not in driver_ids:\n",
    "        driver_ids.append(driver['subject'])\n",
    "print \"Found {} drivers: {}\".format(len(driver_ids), driver_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and validation data tests (split = percentage to have in training set)\n",
    "and then create X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "def create_train_validation_data(driver_list, filter):\n",
    "    #sample = driver_list[driver_list.subject.isin(filter)].ix[:, 'classname':'img']\n",
    "    images = []\n",
    "    labels = []\n",
    "    total = 0\n",
    "    for driver_row in [ drvr for drvr in driver_list[driver_list.subject.isin(filter)].ix[:, 'classname':'img'].iterrows() ]:   # if drvr[1]['subject'] in filter \n",
    "        driver = driver_row[1]  # Drop the index created by the Pandas Dataframe\n",
    "        #print driver\n",
    "        label = int(driver['classname'][1:])\n",
    "        filename = train_images_dir + str(label) + \"/\" + driver['img']\n",
    "        if color_type == 1:\n",
    "            image = cv2.imread(filename, 0).transpose()  # Is the color_type needed here as these are pre-processed images??\n",
    "        elif color_type == 3:\n",
    "            image = cv2.imread(filename).transpose()     # Is the color_type needed here as these are pre-processed images??\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        total += 1\n",
    "        if total % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nProcessed {} rows.\".format(total)\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    images = images.reshape(images.shape[0], color_type, image_width, image_height)\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    labels = np.array(labels, dtype=np.uint8)\n",
    "    labels = np_utils.to_categorical(labels, 10)\n",
    "\n",
    "    return images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_drivers_into_train_and_validate(driver_list, split = 1.0):\n",
    "    driver_valid_list = []\n",
    "    # Take a random sample of drivers into the training list\n",
    "    driver_train_list = np.random.choice(driver_list, int(len(driver_list)*split), replace = False)\n",
    "    # Take the remaining drivers into the validation list\n",
    "    driver_valid_list = [ driver for driver in driver_list if driver not in driver_train_list]\n",
    "    return driver_train_list, driver_valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p024' 'p035' 'p072' 'p045' 'p014' 'p041' 'p016' 'p026' 'p039' 'p015'\n",
      " 'p056' 'p052' 'p081' 'p042' 'p075' 'p064' 'p047' 'p022' 'p050' 'p061'\n",
      " 'p002' 'p066' 'p021' 'p051']\n",
      "['p012', 'p049']\n"
     ]
    }
   ],
   "source": [
    "training_list, validation_list = split_drivers_into_train_and_validate(driver_ids, split = 0.95)\n",
    "print training_list\n",
    "print validation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training/validation data:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Processed 20590 rows.\n",
      "Creating validation data:\n",
      ". . . . . . . . . . . . . . . . . . \n",
      "Processed 1834 rows.\n"
     ]
    }
   ],
   "source": [
    "print \"Creating training/validation data:\"\n",
    "X_train, y_train = create_train_validation_data(driver_list, training_list)\n",
    "print \"Creating validation data:\"\n",
    "X_valid, y_valid = create_train_validation_data(driver_list, validation_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the dimensions / shape of the training and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20996, 1, 224, 224)\n",
      "(20996, 10)\n",
      "(1428, 1, 224, 224)\n",
      "(1428, 10)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "#num_training_samples = X_train.shape[0]\n",
    "print X_valid.shape\n",
    "print y_valid.shape\n",
    "#num_validation_samples = X_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "def load_test_images(test_images_dir):\n",
    "    total = 0\n",
    "    images = []\n",
    "    image_ids = []\n",
    "    test_image_list = os.listdir(test_images_dir)\n",
    "    num_test_images = len(test_image_list)\n",
    "    for i in range(0,num_test_images):\n",
    "        filename = test_images_dir + test_image_list[i]\n",
    "        image = cv2.imread(filename, 0).transpose()  # Is the color_type needed here as these are pre-processed images??\n",
    "        images.append(image)  \n",
    "        image_ids.append(test_image_list[i])\n",
    "        total += 1\n",
    "        if total % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nProcesses {} rows.\".format(total)\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    images = images.reshape(images.shape[0], color_type, image_width, image_height)\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    return images, np.array(image_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Processes 79726 rows.\n",
      "(79726, 1, 224, 224)\n",
      "(79726,)\n"
     ]
    }
   ],
   "source": [
    "test_data, test_ids = load_test_images(test_images_dir)  \n",
    "print test_data.shape\n",
    "print test_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an deep CNN using Keras\n",
    "Starting with no pre-loaded weights though as we'll train this with our own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D  \n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, MaxPooling1D\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Custom Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_keras_model(num_classes, weights_path=None, w_regularizer = None, b_regularizer = None):\n",
    "    num_filters = 8      \n",
    "    num_pooling = 2\n",
    "    num_filters_2 = 8\n",
    "    filter_length = 3     \n",
    "    \n",
    "    # Create callback for history report\n",
    "    from keras.callbacks import Callback\n",
    "    class LossHistory(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "    \n",
    "    \n",
    "    #from keras.utils.dot_utils import Grapher\n",
    "    \n",
    "    model = Sequential()\n",
    "    #grapher = Grapher()\n",
    "\n",
    "    # Now create the NN architecture (version 1)\n",
    "    # Going with colour for now!!\n",
    "    model.add(Convolution2D(num_filters, filter_length, filter_length, border_mode=\"valid\", \n",
    "                        activation=\"relu\", \n",
    "                        W_regularizer = w_regularizer, b_regularizer = b_regularizer,\n",
    "                        input_shape=(color_type, image_width, image_height)))\n",
    "    \n",
    "    # Added\n",
    "    model.add(MaxPooling2D(pool_size=(num_pooling, num_pooling)))  \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(num_filters_2, filter_length, filter_length, \n",
    "                            W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(num_pooling, num_pooling)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, \n",
    "              W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, \n",
    "              W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    if weights_path:\n",
    "        print \"Loading weights from {}\".format(weights_path)\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "\n",
    "    #model.summary()\n",
    "    #grapher.plot(model, 'nn_model.png')\n",
    "    \n",
    "    # TODO - Handle loading existing weights \n",
    "    \n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which NN we are going to use, and whether to load weights or train ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graph_training_loss_history(losses):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(losses)\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('batch')\n",
    "    plt.title('training error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def get_log_loss_score(model, X_valid, y_valid):\n",
    "    predictions_valid = model.predict(X_valid, batch_size=128, verbose=1)\n",
    "    score = log_loss(y_valid, predictions_valid)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Configure the network - only our custom 'LeNet' model is available \n",
    "def compile_model(learning_rate=0.1):\n",
    "    if keras_model == 'custom':\n",
    "        model, LossHistory = custom_keras_model(num_classes, weights, w_regularizer, b_regularizer)\n",
    "        sgd = SGD(lr=learning_rate, decay=0, momentum=0, nesterov=False)\n",
    "        #sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #elif keras_model == 'vgg16':\n",
    "    #    model, LossHistory = vgg16(num_classes, weights)\n",
    "    #    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # Now compile the model\n",
    "    model.compile(loss=loss_function, optimizer=sgd, metrics=['accuracy'])\n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras_model, weights, train_model = 'custom', None, True\n",
    "#keras_model, weights, train_model = 'vgg16', 'model/vgg16_weights.h5', False\n",
    "loss_function='categorical_crossentropy'\n",
    "from keras.regularizers import l1, l2\n",
    "w_regularizer = l2(0.1) # Default = None\n",
    "b_regularizer = l2(0.1) # Default = None\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_21 (Convolution2D) (None, 8, 222, 222)   80          convolution2d_input_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_21 (MaxPooling2D)   (None, 8, 111, 111)   0           convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 8, 111, 111)   0           maxpooling2d_21[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 8, 109, 109)   584         dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 8, 109, 109)   0           convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_22 (MaxPooling2D)   (None, 8, 54, 54)     0           activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 8, 54, 54)     0           maxpooling2d_22[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 23328)         0           dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 128)           2986112     flatten_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 128)           0           dense_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 128)           0           activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 10)            1290        dropout_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 10)            0           dense_22[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 2988066\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"994pt\" viewBox=\"0.00 0.00 236.17 994.00\" width=\"236pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 990)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-990 232.167,-990 232.167,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4621352592 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4621352592</title>\n",
       "<polygon fill=\"none\" points=\"0,-949.5 0,-985.5 228.167,-985.5 228.167,-949.5 0,-949.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-963.3\">convolution2d_input_11 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 4621351632 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4621351632</title>\n",
       "<polygon fill=\"none\" points=\"5.17139,-876.5 5.17139,-912.5 222.996,-912.5 222.996,-876.5 5.17139,-876.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-890.3\">convolution2d_21 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 4621352592&#45;&gt;4621351632 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4621352592-&gt;4621351632</title>\n",
       "<path d=\"M114.083,-949.313C114.083,-941.289 114.083,-931.547 114.083,-922.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-922.529 114.083,-912.529 110.584,-922.529 117.584,-922.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4534758672 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4534758672</title>\n",
       "<polygon fill=\"none\" points=\"5.56104,-803.5 5.56104,-839.5 222.606,-839.5 222.606,-803.5 5.56104,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-817.3\">maxpooling2d_21 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 4621351632&#45;&gt;4534758672 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4621351632-&gt;4534758672</title>\n",
       "<path d=\"M114.083,-876.313C114.083,-868.289 114.083,-858.547 114.083,-849.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-849.529 114.083,-839.529 110.584,-849.529 117.584,-849.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4534759312 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4534759312</title>\n",
       "<polygon fill=\"none\" points=\"44.0645,-730.5 44.0645,-766.5 184.103,-766.5 184.103,-730.5 44.0645,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-744.3\">dropout_31 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4534758672&#45;&gt;4534759312 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4534758672-&gt;4534759312</title>\n",
       "<path d=\"M114.083,-803.313C114.083,-795.289 114.083,-785.547 114.083,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-776.529 114.083,-766.529 110.584,-776.529 117.584,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4525304784 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4525304784</title>\n",
       "<polygon fill=\"none\" points=\"5.17139,-657.5 5.17139,-693.5 222.996,-693.5 222.996,-657.5 5.17139,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-671.3\">convolution2d_22 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 4534759312&#45;&gt;4525304784 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4534759312-&gt;4525304784</title>\n",
       "<path d=\"M114.083,-730.313C114.083,-722.289 114.083,-712.547 114.083,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-703.529 114.083,-693.529 110.584,-703.529 117.584,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4621238416 -->\n",
       "<g class=\"node\" id=\"node6\"><title>4621238416</title>\n",
       "<polygon fill=\"none\" points=\"32.0229,-584.5 32.0229,-620.5 196.144,-620.5 196.144,-584.5 32.0229,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-598.3\">activation_31 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4525304784&#45;&gt;4621238416 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4525304784-&gt;4621238416</title>\n",
       "<path d=\"M114.083,-657.313C114.083,-649.289 114.083,-639.547 114.083,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-630.529 114.083,-620.529 110.584,-630.529 117.584,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4614881360 -->\n",
       "<g class=\"node\" id=\"node7\"><title>4614881360</title>\n",
       "<polygon fill=\"none\" points=\"5.56104,-511.5 5.56104,-547.5 222.606,-547.5 222.606,-511.5 5.56104,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-525.3\">maxpooling2d_22 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 4621238416&#45;&gt;4614881360 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>4621238416-&gt;4614881360</title>\n",
       "<path d=\"M114.083,-584.313C114.083,-576.289 114.083,-566.547 114.083,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-557.529 114.083,-547.529 110.584,-557.529 117.584,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4614885200 -->\n",
       "<g class=\"node\" id=\"node8\"><title>4614885200</title>\n",
       "<polygon fill=\"none\" points=\"44.0645,-438.5 44.0645,-474.5 184.103,-474.5 184.103,-438.5 44.0645,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-452.3\">dropout_32 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4614881360&#45;&gt;4614885200 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>4614881360-&gt;4614885200</title>\n",
       "<path d=\"M114.083,-511.313C114.083,-503.289 114.083,-493.547 114.083,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-484.529 114.083,-474.529 110.584,-484.529 117.584,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4525329168 -->\n",
       "<g class=\"node\" id=\"node9\"><title>4525329168</title>\n",
       "<polygon fill=\"none\" points=\"52.4897,-365.5 52.4897,-401.5 175.677,-401.5 175.677,-365.5 52.4897,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-379.3\">flatten_11 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 4614885200&#45;&gt;4525329168 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>4614885200-&gt;4525329168</title>\n",
       "<path d=\"M114.083,-438.313C114.083,-430.289 114.083,-420.547 114.083,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-411.529 114.083,-401.529 110.584,-411.529 117.584,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4549032976 -->\n",
       "<g class=\"node\" id=\"node10\"><title>4549032976</title>\n",
       "<polygon fill=\"none\" points=\"55.7402,-292.5 55.7402,-328.5 172.427,-328.5 172.427,-292.5 55.7402,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-306.3\">dense_21 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4525329168&#45;&gt;4549032976 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>4525329168-&gt;4549032976</title>\n",
       "<path d=\"M114.083,-365.313C114.083,-357.289 114.083,-347.547 114.083,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-338.529 114.083,-328.529 110.584,-338.529 117.584,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4620668688 -->\n",
       "<g class=\"node\" id=\"node11\"><title>4620668688</title>\n",
       "<polygon fill=\"none\" points=\"32.0229,-219.5 32.0229,-255.5 196.144,-255.5 196.144,-219.5 32.0229,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-233.3\">activation_32 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4549032976&#45;&gt;4620668688 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>4549032976-&gt;4620668688</title>\n",
       "<path d=\"M114.083,-292.313C114.083,-284.289 114.083,-274.547 114.083,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-265.529 114.083,-255.529 110.584,-265.529 117.584,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4618503440 -->\n",
       "<g class=\"node\" id=\"node12\"><title>4618503440</title>\n",
       "<polygon fill=\"none\" points=\"44.0645,-146.5 44.0645,-182.5 184.103,-182.5 184.103,-146.5 44.0645,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-160.3\">dropout_33 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4620668688&#45;&gt;4618503440 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>4620668688-&gt;4618503440</title>\n",
       "<path d=\"M114.083,-219.313C114.083,-211.289 114.083,-201.547 114.083,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-192.529 114.083,-182.529 110.584,-192.529 117.584,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4600561168 -->\n",
       "<g class=\"node\" id=\"node13\"><title>4600561168</title>\n",
       "<polygon fill=\"none\" points=\"55.7402,-73.5 55.7402,-109.5 172.427,-109.5 172.427,-73.5 55.7402,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-87.3\">dense_22 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4618503440&#45;&gt;4600561168 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>4618503440-&gt;4600561168</title>\n",
       "<path d=\"M114.083,-146.313C114.083,-138.289 114.083,-128.547 114.083,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-119.529 114.083,-109.529 110.584,-119.529 117.584,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4600559440 -->\n",
       "<g class=\"node\" id=\"node14\"><title>4600559440</title>\n",
       "<polygon fill=\"none\" points=\"32.0229,-0.5 32.0229,-36.5 196.144,-36.5 196.144,-0.5 32.0229,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.083\" y=\"-14.3\">activation_33 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4600561168&#45;&gt;4600559440 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>4600561168-&gt;4600559440</title>\n",
       "<path d=\"M114.083,-73.3129C114.083,-65.2895 114.083,-55.5475 114.083,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.584,-46.5288 114.083,-36.5288 110.584,-46.5289 117.584,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model so we can get a view of what it looks like\n",
    "# Note we'll do this in each training iteration later, but this'll keep the output tidy!\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "model, LossHistory = compile_model()\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "Train and use validation data to see if we're training effectively!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************\n",
      "\n",
      "Starting training iteration 1 with learning rate 0.001\n",
      "\n",
      "Train on 20996 samples, validate on 1428 samples\n",
      "Epoch 1/10\n",
      "  192/20996 [..............................] - ETA: 448s - loss: 9.6222 - acc: 0.0885"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-fbb1b1c02999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0;31m#shuffle=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m               callbacks=[history])\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# validation_data=(X_train[validation_list], y_train[validation_list]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mgraph_training_loss_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    809\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                         \u001b[0;31m# do not slice the training phase flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mslice_X\u001b[0;34m(X, start, stop)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10 #10\n",
    "learning_rate = [0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "\n",
    "for i in range(0,4):\n",
    "    learningrate = learning_rate[i]\n",
    "    print \"\\n**********************************\"\n",
    "    print \"\\nStarting training iteration {} with learning rate {}\\n\".format(i+1, learningrate)\n",
    "    model, LossHistory = compile_model(learningrate)\n",
    "    history = LossHistory()\n",
    "    #model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=num_epochs,\n",
    "    #          verbose=1, validation_data=(X_valid, y_valid), shuffle=True,\n",
    "    #          callbacks=[history]) \n",
    "    model.fit(X_train, y_train,            \n",
    "              batch_size=batch_size, \n",
    "              nb_epoch=num_epochs,\n",
    "              verbose=1,\n",
    "              #validation_split = 0.10, \n",
    "              #shuffle=True,\n",
    "              validation_data=(X_valid, y_valid), \n",
    "              callbacks=[history])\n",
    "    # validation_data=(X_train[validation_list], y_train[validation_list]),\n",
    "    graph_training_loss_history(history.losses)\n",
    "    model.save_weights('./model/saved_weights_lr_' + str(learningrate)+'.h5')\n",
    "    #print('Score log_loss: ', get_log_loss_score(model, X_valid, y_valid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights('./model/saved_weights_converged.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load the best weights from above\n",
    "In this test, a learning rate of 0.003 worked best, so load this weights file now ready for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('model/saved_weights_lr_0.003.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726/79726 [==============================] - 618s   \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data, batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79726, 10)\n"
     ]
    }
   ],
   "source": [
    "print predictions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.44160431e-05   3.82025178e-07   1.69670984e-05   4.65939729e-06\n",
      "   3.55972916e-05   9.56618726e-01   1.72621831e-02   2.51778644e-02\n",
      "   3.33980424e-05   8.35789600e-04]\n"
     ]
    }
   ],
   "source": [
    "print predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def create_submission(predictions, test_ids, test_info):\n",
    "    result = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result.loc[:, 'img'] = pd.Series(test_ids, index=result.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('submission'):\n",
    "        os.mkdir('submission')\n",
    "    suffix = test_info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('submission', 'submission_' + suffix + '.csv')\n",
    "    result.to_csv(sub_file, index=False)\n",
    "\n",
    "#+ str(score) \\\n",
    "test_info = 'loss_' \\\n",
    "                + '_h_' + str(image_height) \\\n",
    "                + '_w_' + str(image_width) \\\n",
    "                + '_ep_' + str(num_epochs)\n",
    "create_submission(predictions, test_ids, test_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional NN metrics, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the weights, biases, etc. for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W_constraint': None, 'b_constraint': None, 'name': 'convolution2d_3', 'activity_regularizer': None, 'trainable': True, 'dim_ordering': 'th', 'nb_col': 3, 'subsample': (1, 1), 'init': 'glorot_uniform', 'bias': True, 'nb_filter': 8, 'activation': 'relu', 'input_dtype': 'float32', 'batch_input_shape': (None, 1, 224, 224), 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'nb_row': 3, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'border_mode': 'valid'}\n",
      "[array([[[[ 0.15798764, -0.26940349,  0.24715555],\n",
      "         [ 0.13878237, -0.12262621, -0.23275992],\n",
      "         [ 0.16588999,  0.11729886, -0.19583708]]],\n",
      "\n",
      "\n",
      "       [[[-0.73994195, -0.52082288, -0.4964388 ],\n",
      "         [-0.60405433, -0.07172391,  0.60624444],\n",
      "         [ 0.45547041,  0.93813646,  0.81139374]]],\n",
      "\n",
      "\n",
      "       [[[-1.68558943, -1.23065007, -0.18032779],\n",
      "         [-0.14056876,  0.58800739,  0.65498114],\n",
      "         [ 0.34169093,  0.83168703,  0.9269051 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.43811062,  0.49014685, -0.23297071],\n",
      "         [ 0.34388128,  0.13366939, -0.15214261],\n",
      "         [ 0.2354643 , -0.08434661, -0.26753783]]],\n",
      "\n",
      "\n",
      "       [[[ 0.25292528,  0.12966618,  0.18178554],\n",
      "         [ 0.22634226,  0.04379258,  0.26711866],\n",
      "         [-0.34504536,  0.00715635,  0.23054361]]],\n",
      "\n",
      "\n",
      "       [[[ 0.17779198,  0.13328673, -0.06198414],\n",
      "         [-0.04374534,  0.24861899, -0.25968838],\n",
      "         [ 0.2800312 , -0.18131828, -0.1836888 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.42240021,  0.17614986,  0.27706149],\n",
      "         [-0.09610502, -0.08328727, -0.02854088],\n",
      "         [-0.02105968,  0.40895942,  0.0558939 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.03853405,  0.36999056,  0.36529747],\n",
      "         [-0.11962295,  0.07843321,  0.29465654],\n",
      "         [ 0.17400372,  0.26012865, -0.21401981]]]], dtype=float32), array([-0.03621067, -0.20189984, -0.27487698, -0.23507003, -0.31254193,\n",
      "       -0.05420746, -0.1038422 , -0.36736473], dtype=float32)]\n",
      "{'name': 'maxpooling2d_3', 'trainable': True, 'dim_ordering': 'th', 'pool_size': (2, 2), 'strides': (2, 2), 'border_mode': 'valid'}\n",
      "[]\n",
      "{'p': 0.25, 'trainable': True, 'name': 'dropout_4'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'convolution2d_4', 'activity_regularizer': None, 'trainable': True, 'dim_ordering': 'th', 'nb_col': 3, 'subsample': (1, 1), 'init': 'glorot_uniform', 'bias': True, 'nb_filter': 8, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'nb_row': 3, 'activation': 'linear', 'border_mode': 'valid'}\n",
      "[array([[[[ -1.34026662e-01,   8.07377994e-02,  -6.46129847e-02],\n",
      "         [  3.00681740e-02,   1.36504382e-01,  -6.15251511e-02],\n",
      "         [  1.17450215e-01,   4.95707430e-02,   1.02221310e-01]],\n",
      "\n",
      "        [[  5.45655638e-02,   6.99056908e-02,   2.25728944e-01],\n",
      "         [  2.80917704e-01,   3.00262094e-01,   3.97402525e-01],\n",
      "         [  4.27625775e-01,   3.94146234e-01,   2.36574650e-01]],\n",
      "\n",
      "        [[ -1.30582318e-01,   1.37641340e-01,  -3.11150774e-03],\n",
      "         [  3.04710627e-01,   4.22864735e-01,   3.61683100e-01],\n",
      "         [  2.16936961e-01,   7.03835547e-01,   3.48441511e-01]],\n",
      "\n",
      "        [[ -5.06224670e-02,  -6.51089475e-02,   9.91496630e-03],\n",
      "         [ -1.53457731e-01,  -1.50078461e-01,  -1.82722151e-01],\n",
      "         [ -1.12079009e-01,  -1.86909791e-02,   2.29677692e-01]],\n",
      "\n",
      "        [[ -2.55102217e-01,  -6.55690208e-02,  -1.53144613e-01],\n",
      "         [ -1.04985267e-01,  -1.82755385e-02,  -1.27843529e-01],\n",
      "         [  1.78468749e-01,   3.64169814e-02,   1.97013631e-01]],\n",
      "\n",
      "        [[  1.18125446e-01,   3.24146077e-02,  -1.88466311e-01],\n",
      "         [  1.65684819e-01,  -1.52128249e-01,   6.87289834e-02],\n",
      "         [ -1.59715906e-01,  -1.62766337e-01,   3.23500186e-02]],\n",
      "\n",
      "        [[ -5.68162389e-02,  -3.26405019e-02,   1.34382665e-01],\n",
      "         [  1.97662696e-01,   1.95842423e-02,   2.38227904e-01],\n",
      "         [ -7.16538057e-02,  -6.42715394e-03,   2.03806192e-01]],\n",
      "\n",
      "        [[ -2.55695254e-01,  -1.01114467e-01,   1.02877095e-01],\n",
      "         [ -1.38200656e-01,   1.57127261e-01,  -7.51647204e-02],\n",
      "         [ -1.17945140e-02,   1.25966847e-01,   3.86073738e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -1.50935337e-01,  -2.58355513e-02,  -7.69074708e-02],\n",
      "         [  1.70784011e-01,   1.15530536e-01,  -2.00084239e-01],\n",
      "         [  3.54961939e-02,  -1.54196262e-01,   1.02498285e-01]],\n",
      "\n",
      "        [[ -1.71363413e-01,  -7.20096454e-02,   4.22327705e-02],\n",
      "         [ -1.27533423e-02,  -8.46121982e-02,   6.57348707e-02],\n",
      "         [ -2.03400686e-01,   5.65569885e-02,  -1.15443267e-01]],\n",
      "\n",
      "        [[ -6.24200031e-02,  -1.95878670e-02,  -1.56695276e-01],\n",
      "         [ -3.55933746e-03,   4.04093899e-02,  -1.90870002e-01],\n",
      "         [  4.67601344e-02,  -2.58296765e-02,  -4.08654362e-02]],\n",
      "\n",
      "        [[  3.65570895e-02,  -1.37878269e-01,   1.58862285e-02],\n",
      "         [ -1.32701933e-01,  -1.94973558e-01,  -4.47540767e-02],\n",
      "         [ -1.09681875e-01,  -1.00832032e-02,  -1.89619735e-01]],\n",
      "\n",
      "        [[  9.75520760e-02,  -5.13398973e-03,  -1.50441587e-01],\n",
      "         [ -7.41016939e-02,   2.23911479e-02,  -4.85601798e-02],\n",
      "         [ -1.30828306e-01,  -1.24013998e-01,   5.60702384e-02]],\n",
      "\n",
      "        [[  1.10940106e-01,  -1.72561228e-01,  -1.54427975e-01],\n",
      "         [ -6.00919574e-02,  -1.44397080e-01,   1.70612693e-01],\n",
      "         [ -3.39599177e-02,   1.52664900e-01,  -1.27477631e-01]],\n",
      "\n",
      "        [[  7.70184100e-02,  -8.34728554e-02,   8.83945674e-02],\n",
      "         [ -4.76690084e-02,   2.77167261e-02,  -3.22595648e-02],\n",
      "         [ -1.21153958e-01,   3.65889072e-02,   1.60985246e-01]],\n",
      "\n",
      "        [[ -8.21217746e-02,  -1.21021777e-01,   1.61140725e-01],\n",
      "         [  5.27676307e-02,  -6.47312477e-02,  -1.72004938e-01],\n",
      "         [  6.92910627e-02,  -8.20485130e-02,  -6.24316297e-02]]],\n",
      "\n",
      "\n",
      "       [[[  1.40374573e-02,   9.27775800e-02,  -1.34497494e-01],\n",
      "         [ -1.13285601e-01,   1.01350307e-01,  -1.09266132e-01],\n",
      "         [ -1.89159095e-01,   1.98934808e-01,   6.72081187e-02]],\n",
      "\n",
      "        [[  3.27511020e-02,   1.17634967e-01,  -1.27269715e-01],\n",
      "         [  1.52646720e-01,  -1.52425200e-01,   2.25905970e-01],\n",
      "         [  1.64977297e-01,   1.00876026e-01,   2.32137501e-01]],\n",
      "\n",
      "        [[ -1.89209357e-01,   6.58470020e-02,   1.23132303e-01],\n",
      "         [  1.16078347e-01,  -7.57754296e-02,   1.26088351e-01],\n",
      "         [ -2.59809010e-02,  -1.47030175e-01,  -1.33494912e-02]],\n",
      "\n",
      "        [[ -1.80959672e-01,   6.84457645e-02,   4.38374430e-02],\n",
      "         [ -3.80881988e-02,   1.80430397e-01,  -1.51213259e-01],\n",
      "         [ -8.61949101e-02,   6.80425379e-04,  -1.56776741e-01]],\n",
      "\n",
      "        [[ -1.44900247e-01,   7.61443526e-02,  -9.00308266e-02],\n",
      "         [ -1.79905757e-01,   9.18414369e-02,   2.06666104e-02],\n",
      "         [ -1.81725353e-01,  -2.81965174e-02,  -1.76461756e-01]],\n",
      "\n",
      "        [[ -9.68422815e-02,   1.94353789e-01,  -8.60045031e-02],\n",
      "         [  1.30025655e-01,   1.23418614e-01,  -1.69662833e-01],\n",
      "         [  7.54983425e-02,  -1.66469201e-01,   1.02248751e-01]],\n",
      "\n",
      "        [[ -1.56135216e-01,  -7.77975768e-02,   3.57889035e-03],\n",
      "         [ -1.13661572e-01,   2.00226456e-01,  -1.10816173e-01],\n",
      "         [ -1.56880707e-01,   9.26466882e-02,  -3.39139774e-02]],\n",
      "\n",
      "        [[  1.97939172e-01,   1.86556503e-02,   1.08044147e-01],\n",
      "         [  3.53233740e-02,  -2.83028632e-02,  -1.35943890e-01],\n",
      "         [  9.73007753e-02,  -1.10585660e-01,  -4.02854048e-02]]],\n",
      "\n",
      "\n",
      "       [[[  1.61055908e-01,   5.06385677e-02,   1.56299770e-01],\n",
      "         [ -7.59555995e-02,  -1.41047418e-01,   2.03572243e-01],\n",
      "         [ -1.94990680e-01,   3.86845209e-02,  -1.27528459e-01]],\n",
      "\n",
      "        [[ -1.32030740e-01,   1.32898644e-01,  -1.06576219e-01],\n",
      "         [  2.13226959e-01,   3.90804499e-01,   3.54597270e-01],\n",
      "         [  3.79311442e-01,   1.14088640e-01,   4.13883813e-02]],\n",
      "\n",
      "        [[  1.01797327e-01,  -1.87749460e-01,  -1.65094525e-01],\n",
      "         [  7.01736435e-02,   2.65763909e-01,  -2.16975954e-04],\n",
      "         [  4.37777042e-01,   6.18853569e-01,   5.47952414e-01]],\n",
      "\n",
      "        [[ -5.58604188e-02,  -1.71977356e-01,  -1.34098783e-01],\n",
      "         [ -4.43494506e-02,  -2.07404196e-01,   4.17653844e-02],\n",
      "         [  1.55338347e-01,   6.92547411e-02,   1.42531618e-02]],\n",
      "\n",
      "        [[ -9.98816043e-02,  -6.13243282e-02,   1.38340175e-01],\n",
      "         [  1.89429242e-02,  -1.98375389e-01,  -9.86144021e-02],\n",
      "         [ -1.65095404e-01,   4.34281789e-02,   7.87793174e-02]],\n",
      "\n",
      "        [[ -1.83712021e-01,   5.33900708e-02,   1.00747719e-01],\n",
      "         [  4.60998006e-02,  -1.23421304e-01,  -1.51205212e-01],\n",
      "         [  1.35776117e-01,  -8.79866034e-02,  -1.20796710e-01]],\n",
      "\n",
      "        [[ -1.35596409e-01,   1.99403465e-02,   1.60227403e-01],\n",
      "         [  1.03854900e-02,   6.37241527e-02,  -1.64147466e-01],\n",
      "         [  2.47638505e-02,   1.36844024e-01,   9.93079394e-02]],\n",
      "\n",
      "        [[ -1.71116292e-01,  -2.19195053e-01,   6.60874546e-02],\n",
      "         [ -1.60946846e-01,   2.94212606e-02,   1.12008587e-01],\n",
      "         [ -1.15028314e-01,   1.54836625e-01,   2.95663858e-03]]],\n",
      "\n",
      "\n",
      "       [[[  1.32362276e-01,   1.06569901e-01,   7.97002167e-02],\n",
      "         [ -1.68951914e-01,   1.94478199e-01,   7.18228519e-02],\n",
      "         [  4.56590541e-02,   2.06334949e-01,  -7.00459927e-02]],\n",
      "\n",
      "        [[ -2.06193589e-02,  -1.99306086e-01,   1.78816825e-01],\n",
      "         [  2.26207316e-01,   2.24750236e-01,   2.04740569e-01],\n",
      "         [  2.62301505e-01,   3.41759443e-01,  -1.69866495e-02]],\n",
      "\n",
      "        [[ -1.91719130e-01,  -3.45352590e-02,  -7.96410218e-02],\n",
      "         [  1.89501956e-01,   1.05843328e-01,  -8.51246715e-02],\n",
      "         [  2.36440822e-01,   2.31560394e-01,   3.27617496e-01]],\n",
      "\n",
      "        [[  1.41975388e-01,   1.12498410e-01,   1.84779242e-01],\n",
      "         [ -1.24334447e-01,  -1.62688106e-01,  -1.79894045e-01],\n",
      "         [ -1.22840635e-01,  -1.07849659e-02,  -3.98991741e-02]],\n",
      "\n",
      "        [[ -1.80419445e-01,   1.69514656e-01,   7.45791644e-02],\n",
      "         [ -1.86484791e-02,  -6.17312267e-03,  -2.02477083e-01],\n",
      "         [ -7.86445141e-02,   7.56457523e-02,   1.00104837e-02]],\n",
      "\n",
      "        [[  1.16489969e-01,  -1.43883631e-01,  -5.90328313e-02],\n",
      "         [ -7.20457658e-02,  -8.82556662e-02,   5.86984679e-02],\n",
      "         [ -6.20561801e-02,   5.90625033e-02,   1.20547479e-02]],\n",
      "\n",
      "        [[ -1.59494989e-02,  -8.07980821e-02,   1.59984678e-01],\n",
      "         [  2.48661116e-02,  -1.67835474e-01,   8.24318305e-02],\n",
      "         [  5.51037565e-02,   1.56942844e-01,   1.57367855e-01]],\n",
      "\n",
      "        [[  2.01399326e-02,   1.20875001e-01,   1.36484250e-01],\n",
      "         [ -2.17072591e-01,  -1.47154510e-01,  -1.16323180e-01],\n",
      "         [ -1.53657719e-01,   6.20089695e-02,  -2.05865037e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -1.84003681e-01,  -5.40607783e-04,   4.58348840e-02],\n",
      "         [ -7.97649473e-02,   8.76022726e-02,  -1.19890667e-01],\n",
      "         [  1.14465199e-01,  -7.97896758e-02,   1.50145730e-02]],\n",
      "\n",
      "        [[ -1.09362215e-01,   9.58002508e-02,   3.40551674e-01],\n",
      "         [  4.34592813e-01,   4.04127091e-01,   3.97708058e-01],\n",
      "         [  3.69624019e-01,   2.93917626e-01,  -1.12118974e-01]],\n",
      "\n",
      "        [[  2.41007522e-01,   2.15622522e-02,   4.54917341e-01],\n",
      "         [  1.02143042e-01,   7.24775910e-01,   3.35192710e-01],\n",
      "         [  3.65545750e-01,   4.55680519e-01,   1.28989786e-01]],\n",
      "\n",
      "        [[ -1.89654782e-01,   1.07701302e-01,   1.84709281e-01],\n",
      "         [ -1.94947466e-01,  -3.15780528e-02,   3.06993008e-01],\n",
      "         [ -9.39249098e-02,   2.53484219e-01,   3.95917147e-01]],\n",
      "\n",
      "        [[  2.98192296e-02,  -1.55619502e-01,  -1.14066020e-01],\n",
      "         [  2.30198190e-01,   1.64564271e-02,   1.57887310e-01],\n",
      "         [ -5.21433875e-02,  -2.90948451e-02,   2.84163896e-02]],\n",
      "\n",
      "        [[  1.74525589e-01,  -7.19886571e-02,   2.20898818e-02],\n",
      "         [ -1.79628029e-01,   1.20781720e-01,  -1.26591980e-01],\n",
      "         [ -1.36997283e-01,   5.86522818e-02,   1.34458095e-01]],\n",
      "\n",
      "        [[ -3.07309348e-02,  -1.73668727e-01,  -8.87565091e-02],\n",
      "         [  8.61211792e-02,   1.76628619e-01,   2.24475842e-02],\n",
      "         [ -1.33778617e-01,  -5.46995923e-03,  -1.77433297e-01]],\n",
      "\n",
      "        [[  4.59527224e-02,  -1.75031126e-01,  -3.60923335e-02],\n",
      "         [  1.37618929e-01,   3.70100401e-02,   2.19788775e-01],\n",
      "         [  2.32685998e-01,   7.00514838e-02,   1.10160969e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.13152973e-01,  -1.48993567e-01,   1.71904609e-01],\n",
      "         [  1.29477352e-01,   5.91579601e-02,   1.99532613e-01],\n",
      "         [ -5.23704141e-02,  -5.19743450e-02,   7.42700770e-02]],\n",
      "\n",
      "        [[  1.11034058e-01,   6.02700889e-01,   2.23956674e-01],\n",
      "         [  4.45736706e-01,   5.52993655e-01,   2.62173057e-01],\n",
      "         [ -7.91487843e-02,  -1.10755943e-01,  -5.54498024e-02]],\n",
      "\n",
      "        [[  1.07122526e-01,   7.45000184e-01,   4.83212471e-01],\n",
      "         [  7.42595255e-01,   8.16908181e-01,   5.58416069e-01],\n",
      "         [  2.77618259e-01,  -8.51246864e-02,  -4.05674949e-02]],\n",
      "\n",
      "        [[ -1.91775903e-01,  -2.29295850e-01,   2.92701781e-01],\n",
      "         [ -1.79982871e-01,   6.91771805e-02,   3.71467412e-01],\n",
      "         [ -1.30014002e-01,   1.74424142e-01,   1.62393317e-01]],\n",
      "\n",
      "        [[ -5.57390265e-02,   1.82630181e-01,   2.32023478e-01],\n",
      "         [  4.30145636e-02,   3.81959975e-01,   3.73330675e-02],\n",
      "         [  3.01161855e-02,   3.31593335e-01,   2.95552999e-01]],\n",
      "\n",
      "        [[ -1.13248013e-01,   1.17869243e-01,   2.21637830e-01],\n",
      "         [  9.59639102e-02,  -1.17925316e-01,  -6.37454242e-02],\n",
      "         [ -1.32373154e-01,   2.21415028e-01,   2.81448454e-01]],\n",
      "\n",
      "        [[  5.45282029e-02,  -9.47285444e-02,   2.05683902e-01],\n",
      "         [  2.20865399e-01,   2.05022886e-01,   2.08783031e-01],\n",
      "         [  1.78592175e-01,   4.87466976e-02,  -1.22287169e-01]],\n",
      "\n",
      "        [[  1.78463906e-01,  -8.04711506e-02,   2.25818045e-02],\n",
      "         [  4.59423028e-02,   2.60838777e-01,   6.25676140e-02],\n",
      "         [  9.10434648e-02,   3.70032221e-01,   2.46571660e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.89054571e-02,   3.80248576e-02,   1.76263183e-01],\n",
      "         [  5.83530478e-02,  -1.75634861e-01,   2.16807812e-01],\n",
      "         [  1.28080264e-01,  -1.19645678e-01,  -7.97937289e-02]],\n",
      "\n",
      "        [[  3.09628751e-02,   1.88108250e-01,   4.78402734e-01],\n",
      "         [  1.80991516e-01,   5.23348331e-01,   4.94021773e-01],\n",
      "         [ -4.51631732e-02,  -3.43138985e-02,   1.48954883e-01]],\n",
      "\n",
      "        [[  1.87484324e-01,   5.87890565e-01,   4.40616339e-01],\n",
      "         [  3.48017931e-01,   8.31371367e-01,   6.04181349e-01],\n",
      "         [  1.91464618e-01,   4.72599506e-01,  -3.52117643e-02]],\n",
      "\n",
      "        [[ -1.99863270e-01,  -1.57310486e-01,  -1.53482884e-01],\n",
      "         [ -9.24410522e-02,   1.42693624e-01,   3.26830178e-01],\n",
      "         [ -1.16118111e-01,  -3.06452857e-03,   4.72011894e-01]],\n",
      "\n",
      "        [[  7.36609027e-02,   3.51850353e-02,   2.80716997e-02],\n",
      "         [  7.02410191e-02,   1.53118417e-01,   3.34507555e-01],\n",
      "         [  1.64682642e-01,   1.80286631e-01,   4.37131941e-01]],\n",
      "\n",
      "        [[  1.05840258e-01,   1.34482875e-01,  -6.09815270e-02],\n",
      "         [ -1.80161342e-01,   1.03607751e-01,   2.74400622e-01],\n",
      "         [  9.69758853e-02,  -1.13175280e-01,   1.18873142e-01]],\n",
      "\n",
      "        [[  7.07676075e-03,   8.94438401e-02,  -3.84757221e-02],\n",
      "         [  1.30905015e-02,   1.62564263e-01,   1.24399915e-01],\n",
      "         [  1.56307817e-01,  -7.08310306e-02,  -7.95438960e-02]],\n",
      "\n",
      "        [[ -6.38224706e-02,  -8.22534487e-02,   1.87568530e-01],\n",
      "         [  2.24030409e-02,   2.40707353e-01,   2.09672228e-01],\n",
      "         [  4.35993485e-02,   4.55227584e-01,   3.01559776e-01]]]], dtype=float32), array([-0.07912011, -0.00214549,  0.00243343, -0.01269725, -0.03008677,\n",
      "       -0.22036546, -0.36188841, -0.32430181], dtype=float32)]\n",
      "{'activation': 'relu', 'trainable': True, 'name': 'activation_4'}\n",
      "[]\n",
      "{'name': 'maxpooling2d_4', 'trainable': True, 'dim_ordering': 'th', 'pool_size': (2, 2), 'strides': (2, 2), 'border_mode': 'valid'}\n",
      "[]\n",
      "{'p': 0.25, 'trainable': True, 'name': 'dropout_5'}\n",
      "[]\n",
      "{'trainable': True, 'name': 'flatten_2'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'dense_3', 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'activation': 'linear', 'input_dim': None, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'output_dim': 128}\n",
      "[array([[ 0.0121994 , -0.01540998,  0.00822915, ...,  0.00782138,\n",
      "         0.01296692,  0.01324063],\n",
      "       [-0.01087579,  0.00749833,  0.00028079, ..., -0.00603844,\n",
      "         0.00688236, -0.0011218 ],\n",
      "       [ 0.0018305 ,  0.0131845 ,  0.00889361, ...,  0.01216622,\n",
      "        -0.01818432,  0.01242627],\n",
      "       ..., \n",
      "       [ 0.00430395, -0.01503965, -0.0001346 , ..., -0.02233445,\n",
      "         0.01027245, -0.00204884],\n",
      "       [ 0.01497846,  0.00107222, -0.02133265, ..., -0.01487993,\n",
      "        -0.0089016 ,  0.01518229],\n",
      "       [ 0.00076261, -0.01590371,  0.00906142, ..., -0.02610006,\n",
      "        -0.00458856, -0.00711058]], dtype=float32), array([  1.19415554e-03,  -1.29050273e-03,   2.01417413e-03,\n",
      "         7.25443359e-04,  -6.37966616e-04,  -3.42484354e-03,\n",
      "         3.44413170e-03,  -8.99217092e-04,   4.98900423e-03,\n",
      "         6.16313657e-03,  -1.27729421e-04,   2.60804454e-03,\n",
      "        -4.58635762e-03,   3.61107232e-04,   1.85590971e-03,\n",
      "        -6.02681306e-04,   7.98315799e-04,  -1.21205393e-03,\n",
      "        -4.76757111e-03,  -2.06456240e-03,  -2.32479023e-03,\n",
      "        -3.52169760e-03,  -3.03543429e-03,   4.09463607e-03,\n",
      "        -9.86779225e-04,  -2.16885563e-03,  -1.59984594e-03,\n",
      "        -1.86112418e-03,  -5.67875453e-04,  -1.29355059e-03,\n",
      "        -3.09133972e-03,  -8.35817889e-04,   6.17426587e-03,\n",
      "        -1.77123642e-03,  -4.06761217e-04,   6.43647322e-03,\n",
      "        -1.33629376e-03,  -1.34110078e-03,  -1.72654074e-03,\n",
      "         2.19544396e-03,  -1.52935239e-03,   4.57469001e-03,\n",
      "        -7.48313731e-04,   4.33305791e-03,  -6.54535019e-04,\n",
      "        -2.87829316e-03,  -1.19811692e-03,  -1.00214616e-03,\n",
      "        -3.58305406e-04,  -3.15060397e-03,  -1.60349373e-04,\n",
      "         9.87968501e-03,  -1.74027984e-03,   1.02903675e-02,\n",
      "        -2.46593525e-04,   2.64535029e-03,  -8.71906290e-04,\n",
      "        -1.96757517e-03,   3.08088679e-03,  -3.19878967e-03,\n",
      "         6.33344334e-03,  -2.90519954e-03,   5.84115740e-03,\n",
      "        -4.31862049e-04,   4.01016441e-04,   1.62985409e-03,\n",
      "         9.69599409e-04,  -4.40254225e-04,  -1.87514629e-03,\n",
      "         1.34370953e-03,  -3.59619129e-03,  -6.11563795e-04,\n",
      "         2.06638151e-03,  -7.37769878e-04,   3.78458248e-03,\n",
      "         1.11610014e-02,  -2.09250674e-03,   4.51554637e-03,\n",
      "        -2.88349180e-03,  -6.76510623e-04,  -2.56313151e-03,\n",
      "         9.85370111e-03,  -3.75518599e-03,  -1.65990088e-03,\n",
      "         7.15484982e-03,  -3.70519672e-04,   9.61048249e-03,\n",
      "         3.91256704e-04,  -4.53513535e-03,   3.95835936e-03,\n",
      "        -1.93574221e-03,  -1.72964297e-03,   3.38897714e-03,\n",
      "        -8.31536134e-04,   1.00335444e-03,   3.07834079e-03,\n",
      "        -1.83910510e-04,   1.54887536e-03,   1.77319825e-03,\n",
      "        -3.51566734e-04,  -1.46711234e-03,   1.91903883e-03,\n",
      "         3.55987286e-05,   1.09715518e-02,   6.70436211e-03,\n",
      "         6.38626609e-03,  -1.25045842e-03,  -2.72706803e-03,\n",
      "         3.33341677e-03,  -3.85910575e-03,  -1.80140210e-04,\n",
      "         6.07809611e-03,  -1.37493131e-03,  -3.41562531e-03,\n",
      "         5.06167859e-03,   8.09618551e-03,   8.97100603e-04,\n",
      "        -3.08992877e-03,   5.38192515e-04,   6.46606553e-03,\n",
      "         5.63733396e-04,   5.35535766e-03,   6.89913053e-03,\n",
      "         9.82741639e-03,   2.67700339e-03,  -1.90477050e-03,\n",
      "         7.40936142e-04,   3.01471073e-03], dtype=float32)]\n",
      "{'activation': 'relu', 'trainable': True, 'name': 'activation_5'}\n",
      "[]\n",
      "{'p': 0.5, 'trainable': True, 'name': 'dropout_6'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'dense_4', 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'activation': 'linear', 'input_dim': None, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'output_dim': 10}\n",
      "[array([[  1.36285694e-03,  -2.05046614e-03,  -1.74210360e-03, ...,\n",
      "          2.75083847e-04,   1.85915633e-04,  -2.47934647e-03],\n",
      "       [  2.47294120e-05,  -1.95314613e-04,  -6.85804480e-08, ...,\n",
      "          2.16943421e-03,  -1.23392697e-03,  -7.67025806e-04],\n",
      "       [ -2.60666665e-02,  -1.80092528e-02,  -8.77880678e-03, ...,\n",
      "         -1.10833272e-02,   5.24859950e-02,  -5.01799071e-03],\n",
      "       ..., \n",
      "       [ -1.23996083e-02,  -6.10462576e-03,  -1.33603672e-03, ...,\n",
      "         -1.04100420e-03,  -1.33132087e-02,   1.03215709e-01],\n",
      "       [  3.39915697e-03,  -2.23237779e-02,  -2.31061932e-02, ...,\n",
      "         -1.07022021e-02,   2.39834506e-02,   9.75845978e-02],\n",
      "       [ -1.61722880e-02,  -6.29401673e-03,  -9.33710486e-03, ...,\n",
      "         -5.86342486e-03,  -1.82745345e-02,  -4.17539757e-03]], dtype=float32), array([ 0.00467097, -0.00359396,  0.00172842, -0.00901112, -0.00462087,\n",
      "       -0.00676952,  0.00503731,  0.00017666,  0.01025872,  0.0021234 ], dtype=float32)]\n",
      "{'activation': 'softmax', 'trainable': True, 'name': 'activation_6'}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print layer.get_config()\n",
    "    print layer.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused / broken code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Visualise what the CNN has learnt\n",
    "Inspired by https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py and https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'convolution2d_39 '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-f3c6f9e3b7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'convolution2d_39 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlayer_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Number of filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'convolution2d_39 '"
     ]
    }
   ],
   "source": [
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'convolution2d_39 '\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_output = layer_dict[layer_name].output\n",
    "\n",
    "# Number of filters\n",
    "n = 8\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "imsave('stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###VGG16 model\n",
    "From https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "Also see:\n",
    "http://blog.christianperone.com/2016/01/convolutional-hypercolumns-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg16(num_classes, weights_path=None):\n",
    "    \n",
    "    # Create callback for history report\n",
    "    from keras.callbacks import Callback\n",
    "    class LossHistory(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        print \"Loading weights from {}\".format(weights_path)\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "    # Now replace the top layer with one for our own purposes\n",
    "    model.layers.pop()\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    #TODO - Rework model based on \n",
    "    return model, LossHistory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
