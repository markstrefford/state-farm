{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the State Farm image data\n",
    "\n",
    "This notebook provides analysis of the provided State Farm data, using Theano and Keras to build the NN.\n",
    "\n",
    "Note that the data is available from Kaggle here:  \n",
    "https://www.kaggle.com/c/state-farm-distracted-driver-detection/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "First, let's import what we need and set up environment variables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Can't change the value of this config parameter after initialization!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e246e7cb99d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/configparser.pyc\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, cls, val)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_override\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             raise Exception(\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0;34m\"Can't change the value of this config parameter \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \"after initialization!\")\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# print \"SETTING PARAM\", self.fullname,(cls), val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Can't change the value of this config parameter after initialization!"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "theano.config.device = 'gpu'\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports of the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# These are the locations of the images provided by Kaggle\n",
    "# Root Dir is needed for Python, but not for create lmdb shell script later... (we need it there too!)\n",
    "image_root_dir = './imgs/'\n",
    "train_image_source_dir = \"./train/\"\n",
    "test_image_source_dir = \"./test/\"\n",
    "driver_image_list = \"./driver_imgs_list.csv\"\n",
    "\n",
    "# These are the locations of the images that we will work with \n",
    "# Note that as we're continually mix up training and validation drivers/images, \n",
    "# then we will store images in one directory and use code to determine whether to train or validate\n",
    "train_images_dir = \"./images/train/\"\n",
    "#validation_images_dir = \"./images/validate/\" \n",
    "test_images_dir = \"./images/test/\"\n",
    "\n",
    "# Some more controls\n",
    "# color type: 1 - grey, 3 - rgb\n",
    "color_type = 3\n",
    "image_width = 224 #80\n",
    "image_height = 224 #60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start by pre-processing the images\n",
    "There are only 27 different drivers so in order to avoid overfitting, or testing using very similar data to training, we will split the data based on the driver into train and validation sets.\n",
    "\n",
    "Initially though, let's get the list of drivers, see how many images are available for each driver, and which classification they have been labelled with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data summary: \n",
      "  subject classname            img\n",
      "0    p002        c0  img_44733.jpg\n",
      "1    p002        c0  img_72999.jpg\n",
      "2    p002        c0  img_25094.jpg\n",
      "3    p002        c0  img_69092.jpg\n",
      "4    p002        c0  img_92629.jpg\n",
      "\n",
      "Testing data summary: \n",
      "['img_1.jpg', 'img_10.jpg', 'img_100.jpg', 'img_1000.jpg', 'img_100000.jpg', 'img_100001.jpg', 'img_100002.jpg', 'img_100003.jpg', 'img_100004.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Training set is in the provided csv file\n",
    "driver_list = pd.read_csv(driver_image_list)\n",
    "print \"Training data summary: \\n{}\".format(driver_list.head())\n",
    "\n",
    "test_image_list = os.listdir(image_root_dir + test_image_source_dir)\n",
    "print \"\\nTesting data summary: \\n{}\".format(test_image_list[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process images so that they are in an format more suited to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training images found 22424\n"
     ]
    }
   ],
   "source": [
    "def get_driver_images_and_classes(driver_list):\n",
    "    image_list = []\n",
    "    class_list = []\n",
    "    total = 0\n",
    "    for driver_row in [ drvr for drvr in driver_list.iterrows() ]:   # if drvr[1]['subject'] in filter \n",
    "        driver = driver_row[1]  # Drop the index created by the Pandas Dataframe\n",
    "        driver_class = int(driver['classname'][1:])  # Get integer to represent class (eg 'c0' is class '0')\n",
    "        image_list.append(driver['img'])\n",
    "        class_list.append(driver_class)\n",
    "        total += 1\n",
    "    print \"Total number of training images found {}\".format(total)\n",
    "    #Return a list of images and their classification\n",
    "    return np.array(image_list), np.array(class_list)\n",
    "\n",
    "# Create a training list of images and classes from the training set\n",
    "images, classes = get_driver_images_and_classes(driver_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Process the image, for now this is resize only\n",
    "# We'll handle colour/greyscale when we load as cv2 does this for us\n",
    "# TODO - Move to directory creaton to Python code to be OS independent\n",
    "\n",
    "def pre_process_image(image):\n",
    "    processed_img = cv2.resize(image, (image_width, image_height)) \n",
    "    return processed_img\n",
    "    \n",
    "def create_train_image_repository(images_dest_dir, images_list, class_list, color_type=1):\n",
    "    print \"create_image_repository(): Processing images into {}\".format(images_dest_dir)\n",
    "    copied = 0 \n",
    "    for f, c in zip(images_list, class_list):\n",
    "        dest_dir = images_dest_dir + str(c) + \"/\"\n",
    "        if os.path.exists(dest_dir) == False:\n",
    "            !mkdir $dest_dir\n",
    "        image_filename = image_root_dir + train_image_source_dir + '/c' + str(c) + '/' + f\n",
    "        if color_type == 1:\n",
    "            orig_img = cv2.imread(image_filename, 0)\n",
    "        elif color_type == 3:\n",
    "            orig_img = cv2.imread(image_filename)\n",
    "        processed_image = pre_process_image(orig_img)\n",
    "        cv2.imwrite(images_dest_dir + str(c) + \"/\" + f, processed_image)\n",
    "        copied += 1\n",
    "        if copied % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nCopied {} images...Done!\".format(copied)\n",
    "    return copied\n",
    "\n",
    "def create_test_image_repository(dest_dir, images_list, color_type=1):\n",
    "    print \"create_image_repository(): Processing images into {}\".format(dest_dir)\n",
    "    copied = 0 \n",
    "    for f in images_list:\n",
    "        if os.path.exists(dest_dir) == False:\n",
    "            !mkdir $dest_dir\n",
    "        image_filename = image_root_dir + test_image_source_dir + f\n",
    "        if color_type == 1:\n",
    "            orig_img = cv2.imread(image_filename, 0)\n",
    "        elif color_type == 3:\n",
    "            orig_img = cv2.imread(image_filename)\n",
    "        processed_image = pre_process_image(orig_img)\n",
    "        cv2.imwrite(dest_dir + f, processed_image)\n",
    "        copied += 1\n",
    "        if copied % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nCopied {} images...Done!\".format(copied)\n",
    "    return copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process images if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start by clearing out any old data (ignore failures here if the directory doesn't exist)\n",
    "# TODO - Move to Python code to be OS independent\n",
    "\n",
    "create_repository = False    # True forces creation of the processed images, \n",
    "                            # Set to False if this has been done previously\n",
    "if create_repository:\n",
    "    print \"Deleting old repositories if they exist, this may take a while...\"\n",
    "    !rm -rf $train_images_dir\n",
    "    #!rm -rf $validation_images_dir\n",
    "    !rm -rf $test_images_dir\n",
    "\n",
    "    # Create directories\n",
    "    !mkdir -p $train_images_dir\n",
    "    #!mkdir -p $validation_images_dir\n",
    "    !mkdir -p $test_images_dir\n",
    "\n",
    "    create_test_image_repository(test_images_dir, test_image_list, color_type=color_type)\n",
    "    create_train_image_repository(train_images_dir, images, classes, color_type=color_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the drivers into a training and validation set.  To ensure we don't have overfitting (the training set and the validation set contain the same or similar images) we will split on drivers, so a driver can only appear in training or validation but not both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 drivers: ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n"
     ]
    }
   ],
   "source": [
    "driver_ids = []\n",
    "for id, driver in driver_list.iterrows():\n",
    "    if driver['subject'] not in driver_ids:\n",
    "        driver_ids.append(driver['subject'])\n",
    "print \"Found {} drivers: {}\".format(len(driver_ids), driver_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and validation data tests (split = percentage to have in training set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver train list: ['p042' 'p050' 'p064' 'p052' 'p014' 'p045' 'p051' 'p024' 'p075' 'p061'\n",
      " 'p081' 'p012' 'p047' 'p056' 'p066' 'p022' 'p021' 'p072' 'p049' 'p016'\n",
      " 'p015' 'p035' 'p041' 'p002']\n",
      "Driver validation list: ['p026', 'p039']\n"
     ]
    }
   ],
   "source": [
    "def split_drivers_into_train_and_validate(driver_list, split = 0.95):\n",
    "    driver_valid_list = []\n",
    "    # Take a random sample of drivers into the training list\n",
    "    driver_train_list = np.random.choice(driver_list, int(len(driver_list)*split), replace = False)\n",
    "    # Take the remaining drivers into the validation list\n",
    "    driver_valid_list = [ driver for driver in driver_list if driver not in driver_train_list]\n",
    "    return driver_train_list, driver_valid_list\n",
    "    \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_all.ix[rows], student_data[target_col].ix[rows], test_size=test_size)\n",
    "\n",
    "training_list, validation_list = split_drivers_into_train_and_validate(driver_ids)\n",
    "print \"Driver train list: {}\".format(training_list)\n",
    "print \"Driver validation list: {}\".format(validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def render_image(image_filename):\n",
    "    print \"render_image(): Rendering {}\".format(image_filename)\n",
    "    image = cv2.imread(image_filename, color_type_global)\n",
    "    plt.axis(\"off\")\n",
    "    #plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.imshow(image)\n",
    "    plt.show() \n",
    "    #print image.shape\n",
    "    #plt.imshow(image)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training data:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Processed 20577 rows.\n",
      "Creating validation data:\n",
      ". . . . . . . . . . . . . . . . . . \n",
      "Processed 1847 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "def create_train_validation_data(driver_list, filter):\n",
    "    #sample = driver_list[driver_list.subject.isin(filter)].ix[:, 'classname':'img']\n",
    "    images = []\n",
    "    labels = []\n",
    "    total = 0\n",
    "    for driver_row in [ drvr for drvr in driver_list[driver_list.subject.isin(filter)].ix[:, 'classname':'img'].iterrows() ]:   # if drvr[1]['subject'] in filter \n",
    "        driver = driver_row[1]  # Drop the index created by the Pandas Dataframe\n",
    "        #print driver\n",
    "        label = int(driver['classname'][1:])\n",
    "        filename = train_images_dir + str(label) + \"/\" + driver['img']\n",
    "        if color_type == 1:\n",
    "            image = cv2.imread(filename, 0).transpose()  # Is the color_type needed here as these are pre-processed images??\n",
    "        elif color_type == 3:\n",
    "            image = cv2.imread(filename).transpose()     # Is the color_type needed here as these are pre-processed images??\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        total += 1\n",
    "        if total % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nProcessed {} rows.\".format(total)\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    images = images.reshape(images.shape[0], color_type, image_width, image_height)\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    labels = np.array(labels, dtype=np.uint8)\n",
    "    labels = np_utils.to_categorical(labels, 10)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# TODO - Add in random ordering of training data!!\n",
    "# index = np.random.choice(range(0, num_training_samples), num_training_samples, replace = False) # Random ordering\n",
    "# ...driver_list[index], training_list[index]\n",
    "print \"Creating training data:\"\n",
    "X_train, y_train = create_train_validation_data(driver_list, training_list)\n",
    "print \"Creating validation data:\"\n",
    "X_valid, y_valid = create_train_validation_data(driver_list, validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20577, 3, 224, 224)\n",
      "(20577, 10)\n",
      "(1847, 3, 224, 224)\n",
      "(1847, 10)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "num_training_samples = X_train.shape[0]\n",
    "print X_valid.shape\n",
    "print y_valid.shape\n",
    "num_validation_samples = X_valid.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an inital CNN using Keras\n",
    "Starting with no pre-loaded weights though as we'll train this with our own data.\n",
    "Based on example here http://keras.io\n",
    "\n",
    "TODO: In a future iteration, we'll play about with this architecture and the activation, optimizer and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D  \n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, MaxPooling1D\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Custom Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_keras_model(num_classes, weights_path=None):\n",
    "    num_filters = 8      #number of filters to apply/learn in the 1D convolutional layer\n",
    "    num_pooling = 2\n",
    "    filter_length = 2     #linear length of each filter (this is 1D)\n",
    "\n",
    "    # Create callback for history report\n",
    "    from keras.callbacks import Callback\n",
    "    class LossHistory(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "    \n",
    "    \n",
    "    #from keras.utils.dot_utils import Grapher\n",
    "    \n",
    "    model = Sequential()\n",
    "    #grapher = Grapher()\n",
    "\n",
    "    # Now create the NN architecture (version 1)\n",
    "    # Going with colour for now!!\n",
    "    model.add(Convolution2D(num_filters, filter_length, filter_length, border_mode=\"valid\", \n",
    "                        activation=\"relu\", \n",
    "                        input_shape=(color_type, image_width, image_height)))\n",
    "\n",
    "    model.add(Convolution2D(num_filters, filter_length, filter_length))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(num_pooling, num_pooling)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    if weights_path:\n",
    "        print \"Loading weights from {}\".format(weights_path)\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "\n",
    "    #model.summary()\n",
    "    #grapher.plot(model, 'nn_model.png')\n",
    "    \n",
    "    # TODO - Handle loading existing weights \n",
    "    \n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###VGG16 model\n",
    "From https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "Also see:\n",
    "http://blog.christianperone.com/2016/01/convolutional-hypercolumns-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg16(num_classes, weights_path=None):\n",
    "    \n",
    "    # Create callback for history report\n",
    "    from keras.callbacks import Callback\n",
    "    class LossHistory(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        print \"Loading weights from {}\".format(weights_path)\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "    # Now replace the top layer with one for our own purposes\n",
    "    model.layers.pop()\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    #TODO - Rework model based on \n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which NN we are going to use, and whether to load weights or train ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras_model, weights, train_model = 'custom', None, True\n",
    "#keras_model, weights, train_model = 'vgg16', 'model/vgg16_weights.h5', False\n",
    "loss_function='categorical_crossentropy'\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Configure the network\n",
    "\n",
    "if keras_model == 'custom':\n",
    "    model, LossHistory = custom_keras_model(num_classes, weights)\n",
    "    sgd = SGD(lr=0.1, decay=0, momentum=0, nesterov=False)\n",
    "elif keras_model == 'vgg16':\n",
    "    model, LossHistory = vgg16(num_classes, weights)\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Now compile the model\n",
    "model.compile(loss=loss_function, optimizer=sgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 8, 223, 223)   104         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 8, 222, 222)   264         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 8, 222, 222)   0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 8, 111, 111)   0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 8, 111, 111)   0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 98568)         0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           12616832    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128)           0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            1290        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 10)            0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 12618490\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"848pt\" viewBox=\"0.00 0.00 229.68 848.00\" width=\"230pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 844)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-844 225.68,-844 225.68,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4466027536 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4466027536</title>\n",
       "<polygon fill=\"none\" points=\"0,-803.5 0,-839.5 221.68,-839.5 221.68,-803.5 0,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-817.3\">convolution2d_input_1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 4466027216 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4466027216</title>\n",
       "<polygon fill=\"none\" points=\"5.42773,-730.5 5.42773,-766.5 216.252,-766.5 216.252,-730.5 5.42773,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-744.3\">convolution2d_1 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 4466027536&#45;&gt;4466027216 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4466027536-&gt;4466027216</title>\n",
       "<path d=\"M110.84,-803.313C110.84,-795.289 110.84,-785.547 110.84,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-776.529 110.84,-766.529 107.34,-776.529 114.34,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4476912656 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4476912656</title>\n",
       "<polygon fill=\"none\" points=\"5.42773,-657.5 5.42773,-693.5 216.252,-693.5 216.252,-657.5 5.42773,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-671.3\">convolution2d_2 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 4466027216&#45;&gt;4476912656 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4466027216-&gt;4476912656</title>\n",
       "<path d=\"M110.84,-730.313C110.84,-722.289 110.84,-712.547 110.84,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-703.529 110.84,-693.529 107.34,-703.529 114.34,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4477028880 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4477028880</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-584.5 32.2793,-620.5 189.4,-620.5 189.4,-584.5 32.2793,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-598.3\">activation_1 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4476912656&#45;&gt;4477028880 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4476912656-&gt;4477028880</title>\n",
       "<path d=\"M110.84,-657.313C110.84,-649.289 110.84,-639.547 110.84,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-630.529 110.84,-620.529 107.34,-630.529 114.34,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4477159248 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4477159248</title>\n",
       "<polygon fill=\"none\" points=\"5.81738,-511.5 5.81738,-547.5 215.862,-547.5 215.862,-511.5 5.81738,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-525.3\">maxpooling2d_1 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 4477028880&#45;&gt;4477159248 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4477028880-&gt;4477159248</title>\n",
       "<path d=\"M110.84,-584.313C110.84,-576.289 110.84,-566.547 110.84,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-557.529 110.84,-547.529 107.34,-557.529 114.34,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4477276560 -->\n",
       "<g class=\"node\" id=\"node6\"><title>4477276560</title>\n",
       "<polygon fill=\"none\" points=\"44.3208,-438.5 44.3208,-474.5 177.359,-474.5 177.359,-438.5 44.3208,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-452.3\">dropout_1 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4477159248&#45;&gt;4477276560 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4477159248-&gt;4477276560</title>\n",
       "<path d=\"M110.84,-511.313C110.84,-503.289 110.84,-493.547 110.84,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-484.529 110.84,-474.529 107.34,-484.529 114.34,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4477669264 -->\n",
       "<g class=\"node\" id=\"node7\"><title>4477669264</title>\n",
       "<polygon fill=\"none\" points=\"52.4897,-365.5 52.4897,-401.5 169.19,-401.5 169.19,-365.5 52.4897,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-379.3\">flatten_1 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 4477276560&#45;&gt;4477669264 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>4477276560-&gt;4477669264</title>\n",
       "<path d=\"M110.84,-438.313C110.84,-430.289 110.84,-420.547 110.84,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-411.529 110.84,-401.529 107.34,-411.529 114.34,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4478446032 -->\n",
       "<g class=\"node\" id=\"node8\"><title>4478446032</title>\n",
       "<polygon fill=\"none\" points=\"55.9966,-292.5 55.9966,-328.5 165.683,-328.5 165.683,-292.5 55.9966,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-306.3\">dense_1 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4477669264&#45;&gt;4478446032 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>4477669264-&gt;4478446032</title>\n",
       "<path d=\"M110.84,-365.313C110.84,-357.289 110.84,-347.547 110.84,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-338.529 110.84,-328.529 107.34,-338.529 114.34,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4478505232 -->\n",
       "<g class=\"node\" id=\"node9\"><title>4478505232</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-219.5 32.2793,-255.5 189.4,-255.5 189.4,-219.5 32.2793,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-233.3\">activation_2 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4478446032&#45;&gt;4478505232 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>4478446032-&gt;4478505232</title>\n",
       "<path d=\"M110.84,-292.313C110.84,-284.289 110.84,-274.547 110.84,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-265.529 110.84,-255.529 107.34,-265.529 114.34,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4478506256 -->\n",
       "<g class=\"node\" id=\"node10\"><title>4478506256</title>\n",
       "<polygon fill=\"none\" points=\"44.3208,-146.5 44.3208,-182.5 177.359,-182.5 177.359,-146.5 44.3208,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-160.3\">dropout_2 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4478505232&#45;&gt;4478506256 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>4478505232-&gt;4478506256</title>\n",
       "<path d=\"M110.84,-219.313C110.84,-211.289 110.84,-201.547 110.84,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-192.529 110.84,-182.529 107.34,-192.529 114.34,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4478549072 -->\n",
       "<g class=\"node\" id=\"node11\"><title>4478549072</title>\n",
       "<polygon fill=\"none\" points=\"55.9966,-73.5 55.9966,-109.5 165.683,-109.5 165.683,-73.5 55.9966,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-87.3\">dense_2 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4478506256&#45;&gt;4478549072 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>4478506256-&gt;4478549072</title>\n",
       "<path d=\"M110.84,-146.313C110.84,-138.289 110.84,-128.547 110.84,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-119.529 110.84,-109.529 107.34,-119.529 114.34,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4478548176 -->\n",
       "<g class=\"node\" id=\"node12\"><title>4478548176</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-0.5 32.2793,-36.5 189.4,-36.5 189.4,-0.5 32.2793,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-14.3\">activation_3 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4478549072&#45;&gt;4478548176 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>4478549072-&gt;4478548176</title>\n",
       "<path d=\"M110.84,-73.3129C110.84,-65.2895 110.84,-55.5475 110.84,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-46.5288 110.84,-36.5288 107.34,-46.5289 114.34,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "Train and use validation data to see if we're training effectively!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20577 samples, validate on 1847 samples\n",
      "Epoch 1/1\n",
      "20577/20577 [==============================] - 19874s - loss: 2.3113 - val_loss: 2.3237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/keras/models.py:603: UserWarning: The \"show_accuracy\" argument is deprecated, instead you should pass the \"accuracy\" metric to the model at compile time:\n",
      "`model.compile(optimizer, loss, metrics=[\"accuracy\"])`\n",
      "  warnings.warn('The \"show_accuracy\" argument is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131894210>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "\n",
    "history = LossHistory()\n",
    "#index = np.random.choice(range(0, num_training_samples), num_training_samples, replace = False) # Random ordering\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=num_epochs,\n",
    "              show_accuracy=True, verbose=1, validation_data=(X_valid, y_valid), \n",
    "              callbacks=[history])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAADhCAYAAAA05ulEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCQ3DMAwjMyY0DMMwjMz8f8vgByyGnSFnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131894ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def graph_training_loss_history(losses):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(losses)\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('batch')\n",
    "    plt.title('training error')\n",
    "    plt.show()\n",
    "    \n",
    "graph_training_loss_history(history.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO : Add in model.load_weights(filename) here at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755/1755 [==============================] - 1s     \n",
      "('Score log_loss: ', 2.2638033781433351)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "predictions_valid = model.predict(X_valid, batch_size=128, verbose=1)\n",
    "score = log_loss(y_valid, predictions_valid)\n",
    "print('Score log_loss: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./model/saved_weights_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "def load_test_images(test_images_dir):\n",
    "    total = 0\n",
    "    images = []\n",
    "    image_ids = []\n",
    "    test_image_list = os.listdir(test_images_dir)\n",
    "    num_test_images = len(test_image_list)\n",
    "    for i in range(0,num_test_images):\n",
    "        filename = test_images_dir + test_image_list[i]\n",
    "        image = cv2.imread(filename, 0).transpose()  # Is the color_type needed here as these are pre-processed images??\n",
    "        images.append(image)  \n",
    "        image_ids.append(test_image_list[i])\n",
    "        total += 1\n",
    "        if total % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nProcesses {} rows.\".format(total)\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    images = images.reshape(images.shape[0], color_type, image_width, image_height)\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    return images, np.array(image_ids)\n",
    "\n",
    "#test_image_batches = split_test_data(test_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Processes 79726 rows.\n",
      "(79726, 1, 80, 60)\n",
      "(79726,)\n"
     ]
    }
   ],
   "source": [
    "test_data, test_ids = load_test_images(test_images_dir)  \n",
    "print test_data.shape\n",
    "print test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726/79726 [==============================] - 55s    \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data, batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79726, 10)\n"
     ]
    }
   ],
   "source": [
    "print predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def create_submission(predictions, test_ids, test_info):\n",
    "    result = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result.loc[:, 'img'] = pd.Series(test_ids, index=result.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('submission'):\n",
    "        os.mkdir('submission')\n",
    "    suffix = test_info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('submission', 'submission_' + suffix + '.csv')\n",
    "    result.to_csv(sub_file, index=False)\n",
    "\n",
    "test_info = 'loss_' + str(score) \\\n",
    "                + '_h_' + str(image_height) \\\n",
    "                + '_w_' + str(image_width) \\\n",
    "                + '_ep_' + str(num_epochs)\n",
    "create_submission(predictions, test_ids, test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
