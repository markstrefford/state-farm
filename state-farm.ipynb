{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the State Farm image data\n",
    "\n",
    "This notebook provides analysis of the provided State Farm data, using Theano and Keras to build the NN.\n",
    "\n",
    "Note that the data is available from Kaggle here:  \n",
    "https://www.kaggle.com/c/state-farm-distracted-driver-detection/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "First, let's import what we need and set up environment variables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Can't change the value of this config parameter after initialization!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e246e7cb99d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/configparser.pyc\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, cls, val)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_override\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             raise Exception(\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0;34m\"Can't change the value of this config parameter \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \"after initialization!\")\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# print \"SETTING PARAM\", self.fullname,(cls), val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Can't change the value of this config parameter after initialization!"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "theano.config.device = 'gpu'\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports of the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# These are the locations of the images provided by Kaggle\n",
    "# Root Dir is needed for Python, but not for create lmdb shell script later... (we need it there too!)\n",
    "image_root_dir = './imgs/'\n",
    "train_image_source_dir = \"./train/\"\n",
    "test_image_source_dir = \"./test/\"\n",
    "driver_image_list = \"./driver_imgs_list.csv\"\n",
    "\n",
    "# These are the locations of the images that we will work with \n",
    "# Note that as we're continually mix up training and validation drivers/images, \n",
    "# then we will store images in one directory and use code to determine whether to train or validate\n",
    "train_images_dir = \"./images/train/\"\n",
    "#validation_images_dir = \"./images/validate/\" \n",
    "test_images_dir = \"./images/test/\"\n",
    "\n",
    "# Some more controls\n",
    "# color type: 1 - grey, 3 - rgb\n",
    "color_type = 1 \n",
    "image_width = 224 #80\n",
    "image_height = 224 #60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start by pre-processing the images\n",
    "There are only 27 different drivers so in order to avoid overfitting, or testing using very similar data to training, we will split the data based on the driver into train and validation sets.\n",
    "\n",
    "Initially though, let's get the list of drivers, see how many images are available for each driver, and which classification they have been labelled with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data summary: \n",
      "  subject classname            img\n",
      "0    p002        c0  img_44733.jpg\n",
      "1    p002        c0  img_72999.jpg\n",
      "2    p002        c0  img_25094.jpg\n",
      "3    p002        c0  img_69092.jpg\n",
      "4    p002        c0  img_92629.jpg\n",
      "\n",
      "Testing data summary: \n",
      "['img_1.jpg', 'img_10.jpg', 'img_100.jpg', 'img_1000.jpg', 'img_100000.jpg', 'img_100001.jpg', 'img_100002.jpg', 'img_100003.jpg', 'img_100004.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Training set is in the provided csv file\n",
    "driver_list = pd.read_csv(driver_image_list)\n",
    "print \"Training data summary: \\n{}\".format(driver_list.head())\n",
    "\n",
    "test_image_list = os.listdir(image_root_dir + test_image_source_dir)\n",
    "print \"\\nTesting data summary: \\n{}\".format(test_image_list[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process images so that they are in an format more suited to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training images found 22424\n"
     ]
    }
   ],
   "source": [
    "def get_driver_images_and_classes(driver_list):\n",
    "    image_list = []\n",
    "    class_list = []\n",
    "    total = 0\n",
    "    for driver_row in [ drvr for drvr in driver_list.iterrows() ]:   # if drvr[1]['subject'] in filter \n",
    "        driver = driver_row[1]  # Drop the index created by the Pandas Dataframe\n",
    "        driver_class = int(driver['classname'][1:])  # Get integer to represent class (eg 'c0' is class '0')\n",
    "        image_list.append(driver['img'])\n",
    "        class_list.append(driver_class)\n",
    "        total += 1\n",
    "    print \"Total number of training images found {}\".format(total)\n",
    "    #Return a list of images and their classification\n",
    "    return np.array(image_list), np.array(class_list)\n",
    "\n",
    "# Create a training list of images and classes from the training set\n",
    "images, classes = get_driver_images_and_classes(driver_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Process the image, for now this is resize only\n",
    "# We'll handle colour/greyscale when we load as cv2 does this for us\n",
    "# TODO - Move directory creation to Python code to be OS independent\n",
    "\n",
    "def pre_process_image(image):\n",
    "    processed_img = cv2.resize(image, (image_width, image_height)) \n",
    "    return processed_img\n",
    "    \n",
    "def create_train_image_repository(images_dest_dir, images_list, class_list, color_type=1):\n",
    "    print \"create_image_repository(): Processing images into {}\".format(images_dest_dir)\n",
    "    copied = 0 \n",
    "    for f, c in zip(images_list, class_list):\n",
    "        dest_dir = images_dest_dir + str(c) + \"/\"\n",
    "        if os.path.exists(dest_dir) == False:\n",
    "            !mkdir $dest_dir\n",
    "        image_filename = image_root_dir + train_image_source_dir + '/c' + str(c) + '/' + f\n",
    "        if color_type == 1:\n",
    "            orig_img = cv2.imread(image_filename, 0)\n",
    "        elif color_type == 3:\n",
    "            orig_img = cv2.imread(image_filename)\n",
    "        processed_image = pre_process_image(orig_img)\n",
    "        cv2.imwrite(images_dest_dir + str(c) + \"/\" + f, processed_image)\n",
    "        copied += 1\n",
    "        if copied % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nCopied {} images...Done!\".format(copied)\n",
    "    return copied\n",
    "\n",
    "def create_test_image_repository(dest_dir, images_list, color_type=1):\n",
    "    print \"create_image_repository(): Processing images into {}\".format(dest_dir)\n",
    "    copied = 0 \n",
    "    for f in images_list:\n",
    "        if os.path.exists(dest_dir) == False:\n",
    "            !mkdir $dest_dir\n",
    "        image_filename = image_root_dir + test_image_source_dir + f\n",
    "        if color_type == 1:\n",
    "            orig_img = cv2.imread(image_filename, 0)\n",
    "        elif color_type == 3:\n",
    "            orig_img = cv2.imread(image_filename)\n",
    "        processed_image = pre_process_image(orig_img)\n",
    "        cv2.imwrite(dest_dir + f, processed_image)\n",
    "        copied += 1\n",
    "        if copied % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nCopied {} images...Done!\".format(copied)\n",
    "    return copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process images if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start by clearing out any old data (ignore failures here if the directory doesn't exist)\n",
    "# TODO - Move to Python code to be OS independent\n",
    "\n",
    "create_repository = False    # True forces creation of the processed images, \n",
    "                            # Set to False if this has been done previously\n",
    "if create_repository:\n",
    "    print \"Deleting old repositories if they exist, this may take a while...\"\n",
    "    !rm -rf $train_images_dir\n",
    "    #!rm -rf $validation_images_dir\n",
    "    !rm -rf $test_images_dir\n",
    "\n",
    "    # Create directories\n",
    "    !mkdir -p $train_images_dir\n",
    "    #!mkdir -p $validation_images_dir\n",
    "    !mkdir -p $test_images_dir\n",
    "\n",
    "    create_test_image_repository(test_images_dir, test_image_list, color_type=color_type)\n",
    "    create_train_image_repository(train_images_dir, images, classes, color_type=color_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, validation and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the drivers into a training and validation set.  To ensure we don't have overfitting (the training set and the validation set contain the same or similar images) we will split on drivers, so a driver can only appear in training or validation but not both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 drivers: ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n"
     ]
    }
   ],
   "source": [
    "driver_ids = []\n",
    "for id, driver in driver_list.iterrows():\n",
    "    if driver['subject'] not in driver_ids:\n",
    "        driver_ids.append(driver['subject'])\n",
    "print \"Found {} drivers: {}\".format(len(driver_ids), driver_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def render_image(image_filename):\n",
    "    print \"render_image(): Rendering {}\".format(image_filename)\n",
    "    image = cv2.imread(image_filename, color_type_global)\n",
    "    plt.axis(\"off\")\n",
    "    #plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.imshow(image)\n",
    "    plt.show() \n",
    "    #print image.shape\n",
    "    #plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and validation data tests (split = percentage to have in training set)\n",
    "and then create X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "def create_train_validation_data(driver_list, filter):\n",
    "    #sample = driver_list[driver_list.subject.isin(filter)].ix[:, 'classname':'img']\n",
    "    images = []\n",
    "    labels = []\n",
    "    total = 0\n",
    "    for driver_row in [ drvr for drvr in driver_list[driver_list.subject.isin(filter)].ix[:, 'classname':'img'].iterrows() ]:   # if drvr[1]['subject'] in filter \n",
    "        driver = driver_row[1]  # Drop the index created by the Pandas Dataframe\n",
    "        #print driver\n",
    "        label = int(driver['classname'][1:])\n",
    "        filename = train_images_dir + str(label) + \"/\" + driver['img']\n",
    "        if color_type == 1:\n",
    "            image = cv2.imread(filename, 0).transpose()  # Is the color_type needed here as these are pre-processed images??\n",
    "        elif color_type == 3:\n",
    "            image = cv2.imread(filename).transpose()     # Is the color_type needed here as these are pre-processed images??\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        total += 1\n",
    "        if total % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nProcessed {} rows.\".format(total)\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    images = images.reshape(images.shape[0], color_type, image_width, image_height)\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    labels = np.array(labels, dtype=np.uint8)\n",
    "    labels = np_utils.to_categorical(labels, 10)\n",
    "\n",
    "    return images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_drivers_into_train_and_validate(driver_list, split = 1.0):\n",
    "    driver_valid_list = []\n",
    "    # Take a random sample of drivers into the training list\n",
    "    driver_train_list = np.random.choice(driver_list, int(len(driver_list)*split), replace = False)\n",
    "    # Take the remaining drivers into the validation list\n",
    "    driver_valid_list = [ driver for driver in driver_list if driver not in driver_train_list]\n",
    "    return driver_train_list, driver_valid_list\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training/validation data:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Processed 22424 rows.\n"
     ]
    }
   ],
   "source": [
    "print \"Creating training/validation data:\"\n",
    "X_train, y_train = create_train_validation_data(driver_list, driver_ids)\n",
    "#print \"Creating validation data:\"\n",
    "#X_valid, y_valid = create_train_validation_data(driver_list, validation_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 1, 224, 224)\n",
      "(22424, 10)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "#num_training_samples = X_train.shape[0]\n",
    "#print X_valid.shape\n",
    "#print y_valid.shape\n",
    "#num_validation_samples = X_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . "
     ]
    }
   ],
   "source": [
    "test_data, test_ids = load_test_images(test_images_dir)  \n",
    "print test_data.shape\n",
    "print test_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an inital CNN using Keras\n",
    "Starting with no pre-loaded weights though as we'll train this with our own data.\n",
    "Based on example here http://keras.io\n",
    "\n",
    "TODO: In a future iteration, we'll play about with this architecture and the activation, optimizer and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D  \n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, MaxPooling1D\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Custom Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_keras_model(num_classes, weights_path=None, w_regularizer = None, b_regularizer = None):\n",
    "    num_filters = 8      #number of filters to apply/learn in the 1D convolutional layer\n",
    "    num_pooling = 2\n",
    "    #filter_length = 5     #linear length of each filter (this is 1D)\n",
    "    num_filters_2 = 8\n",
    "\n",
    "    #num_filters = 8      #number of filters to apply/learn in the 1D convolutional layer\n",
    "    #num_pooling = 2\n",
    "    filter_length = 3     #linear length of each filter (this is 1D)\n",
    "    #num_filters_2 = 16\n",
    "    \n",
    "    # Create callback for history report\n",
    "    from keras.callbacks import Callback\n",
    "    class LossHistory(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "    \n",
    "    \n",
    "    #from keras.utils.dot_utils import Grapher\n",
    "    \n",
    "    model = Sequential()\n",
    "    #grapher = Grapher()\n",
    "\n",
    "    # Now create the NN architecture (version 1)\n",
    "    # Going with colour for now!!\n",
    "    model.add(Convolution2D(num_filters, filter_length, filter_length, border_mode=\"valid\", \n",
    "                        activation=\"relu\", \n",
    "                        W_regularizer = w_regularizer, b_regularizer = b_regularizer,\n",
    "                        input_shape=(color_type, image_width, image_height)))\n",
    "    \n",
    "    # Added\n",
    "    model.add(MaxPooling2D(pool_size=(num_pooling, num_pooling)))  \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(num_filters_2, filter_length, filter_length, \n",
    "                            W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(num_pooling, num_pooling)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, \n",
    "              W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, \n",
    "              W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    if weights_path:\n",
    "        print \"Loading weights from {}\".format(weights_path)\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "\n",
    "    #model.summary()\n",
    "    #grapher.plot(model, 'nn_model.png')\n",
    "    \n",
    "    # TODO - Handle loading existing weights \n",
    "    \n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which NN we are going to use, and whether to load weights or train ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graph_training_loss_history(losses):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(losses)\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('batch')\n",
    "    plt.title('training error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def get_log_loss_score(model, X_valid, y_valid):\n",
    "    predictions_valid = model.predict(X_valid, batch_size=128, verbose=1)\n",
    "    score = log_loss(y_valid, predictions_valid)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Configure the network\n",
    "def compile_model(learning_rate=0.1):\n",
    "    if keras_model == 'custom':\n",
    "        model, LossHistory = custom_keras_model(num_classes, weights, w_regularizer, b_regularizer)\n",
    "        sgd = SGD(lr=learning_rate, decay=0, momentum=0, nesterov=False)\n",
    "        #sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    elif keras_model == 'vgg16':\n",
    "        model, LossHistory = vgg16(num_classes, weights)\n",
    "        sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # Now compile the model\n",
    "    model.compile(loss=loss_function, optimizer=sgd, metrics=['accuracy'])\n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras_model, weights, train_model = 'custom', None, True\n",
    "#keras_model, weights, train_model = 'vgg16', 'model/vgg16_weights.h5', False\n",
    "loss_function='categorical_crossentropy'\n",
    "from keras.regularizers import l1, l2\n",
    "w_regularizer = l2(0.1) # Default = None\n",
    "b_regularizer = l2(0.1) # Default = None\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_23 (Convolution2D) (None, 8, 222, 222)   80          convolution2d_input_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_23 (MaxPooling2D)   (None, 8, 111, 111)   0           convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 8, 111, 111)   0           maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 8, 109, 109)   584         dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 8, 109, 109)   0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_24 (MaxPooling2D)   (None, 8, 54, 54)     0           activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 8, 54, 54)     0           maxpooling2d_24[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 23328)         0           dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 128)           2986112     flatten_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 128)           0           dense_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 128)           0           activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 10)            1290        dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 10)            0           dense_24[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 2988066\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"994pt\" viewBox=\"0.00 0.00 236.68 994.00\" width=\"237pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 990)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-990 232.68,-990 232.68,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4516868048 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4516868048</title>\n",
       "<polygon fill=\"none\" points=\"0,-949.5 0,-985.5 228.68,-985.5 228.68,-949.5 0,-949.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-963.3\">convolution2d_input_12 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 4516867856 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4516867856</title>\n",
       "<polygon fill=\"none\" points=\"5.42773,-876.5 5.42773,-912.5 223.252,-912.5 223.252,-876.5 5.42773,-876.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-890.3\">convolution2d_23 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 4516868048&#45;&gt;4516867856 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4516868048-&gt;4516867856</title>\n",
       "<path d=\"M114.34,-949.313C114.34,-941.289 114.34,-931.547 114.34,-922.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-922.529 114.34,-912.529 110.84,-922.529 117.84,-922.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4583382096 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4583382096</title>\n",
       "<polygon fill=\"none\" points=\"5.81738,-803.5 5.81738,-839.5 222.862,-839.5 222.862,-803.5 5.81738,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-817.3\">maxpooling2d_23 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 4516867856&#45;&gt;4583382096 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4516867856-&gt;4583382096</title>\n",
       "<path d=\"M114.34,-876.313C114.34,-868.289 114.34,-858.547 114.34,-849.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-849.529 114.34,-839.529 110.84,-849.529 117.84,-849.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4583380624 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4583380624</title>\n",
       "<polygon fill=\"none\" points=\"44.3208,-730.5 44.3208,-766.5 184.359,-766.5 184.359,-730.5 44.3208,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-744.3\">dropout_34 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4583382096&#45;&gt;4583380624 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4583382096-&gt;4583380624</title>\n",
       "<path d=\"M114.34,-803.313C114.34,-795.289 114.34,-785.547 114.34,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-776.529 114.34,-766.529 110.84,-776.529 117.84,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4516594768 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4516594768</title>\n",
       "<polygon fill=\"none\" points=\"5.42773,-657.5 5.42773,-693.5 223.252,-693.5 223.252,-657.5 5.42773,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-671.3\">convolution2d_24 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 4583380624&#45;&gt;4516594768 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4583380624-&gt;4516594768</title>\n",
       "<path d=\"M114.34,-730.313C114.34,-722.289 114.34,-712.547 114.34,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-703.529 114.34,-693.529 110.84,-703.529 117.84,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4608947472 -->\n",
       "<g class=\"node\" id=\"node6\"><title>4608947472</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-584.5 32.2793,-620.5 196.4,-620.5 196.4,-584.5 32.2793,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-598.3\">activation_34 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4516594768&#45;&gt;4608947472 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4516594768-&gt;4608947472</title>\n",
       "<path d=\"M114.34,-657.313C114.34,-649.289 114.34,-639.547 114.34,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-630.529 114.34,-620.529 110.84,-630.529 117.84,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4608892496 -->\n",
       "<g class=\"node\" id=\"node7\"><title>4608892496</title>\n",
       "<polygon fill=\"none\" points=\"5.81738,-511.5 5.81738,-547.5 222.862,-547.5 222.862,-511.5 5.81738,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-525.3\">maxpooling2d_24 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 4608947472&#45;&gt;4608892496 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>4608947472-&gt;4608892496</title>\n",
       "<path d=\"M114.34,-584.313C114.34,-576.289 114.34,-566.547 114.34,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-557.529 114.34,-547.529 110.84,-557.529 117.84,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4608892304 -->\n",
       "<g class=\"node\" id=\"node8\"><title>4608892304</title>\n",
       "<polygon fill=\"none\" points=\"44.3208,-438.5 44.3208,-474.5 184.359,-474.5 184.359,-438.5 44.3208,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-452.3\">dropout_35 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4608892496&#45;&gt;4608892304 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>4608892496-&gt;4608892304</title>\n",
       "<path d=\"M114.34,-511.313C114.34,-503.289 114.34,-493.547 114.34,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-484.529 114.34,-474.529 110.84,-484.529 117.84,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4608949200 -->\n",
       "<g class=\"node\" id=\"node9\"><title>4608949200</title>\n",
       "<polygon fill=\"none\" points=\"52.4897,-365.5 52.4897,-401.5 176.19,-401.5 176.19,-365.5 52.4897,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-379.3\">flatten_12 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 4608892304&#45;&gt;4608949200 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>4608892304-&gt;4608949200</title>\n",
       "<path d=\"M114.34,-438.313C114.34,-430.289 114.34,-420.547 114.34,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-411.529 114.34,-401.529 110.84,-411.529 117.84,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4610127504 -->\n",
       "<g class=\"node\" id=\"node10\"><title>4610127504</title>\n",
       "<polygon fill=\"none\" points=\"55.9966,-292.5 55.9966,-328.5 172.683,-328.5 172.683,-292.5 55.9966,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-306.3\">dense_23 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4608949200&#45;&gt;4610127504 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>4608949200-&gt;4610127504</title>\n",
       "<path d=\"M114.34,-365.313C114.34,-357.289 114.34,-347.547 114.34,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-338.529 114.34,-328.529 110.84,-338.529 117.84,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4610125968 -->\n",
       "<g class=\"node\" id=\"node11\"><title>4610125968</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-219.5 32.2793,-255.5 196.4,-255.5 196.4,-219.5 32.2793,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-233.3\">activation_35 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4610127504&#45;&gt;4610125968 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>4610127504-&gt;4610125968</title>\n",
       "<path d=\"M114.34,-292.313C114.34,-284.289 114.34,-274.547 114.34,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-265.529 114.34,-255.529 110.84,-265.529 117.84,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4609677712 -->\n",
       "<g class=\"node\" id=\"node12\"><title>4609677712</title>\n",
       "<polygon fill=\"none\" points=\"44.3208,-146.5 44.3208,-182.5 184.359,-182.5 184.359,-146.5 44.3208,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-160.3\">dropout_36 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4610125968&#45;&gt;4609677712 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>4610125968-&gt;4609677712</title>\n",
       "<path d=\"M114.34,-219.313C114.34,-211.289 114.34,-201.547 114.34,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-192.529 114.34,-182.529 110.84,-192.529 117.84,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4610237776 -->\n",
       "<g class=\"node\" id=\"node13\"><title>4610237776</title>\n",
       "<polygon fill=\"none\" points=\"55.9966,-73.5 55.9966,-109.5 172.683,-109.5 172.683,-73.5 55.9966,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-87.3\">dense_24 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4609677712&#45;&gt;4610237776 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>4609677712-&gt;4610237776</title>\n",
       "<path d=\"M114.34,-146.313C114.34,-138.289 114.34,-128.547 114.34,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-119.529 114.34,-109.529 110.84,-119.529 117.84,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4610239120 -->\n",
       "<g class=\"node\" id=\"node14\"><title>4610239120</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-0.5 32.2793,-36.5 196.4,-36.5 196.4,-0.5 32.2793,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.34\" y=\"-14.3\">activation_36 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4610237776&#45;&gt;4610239120 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>4610237776-&gt;4610239120</title>\n",
       "<path d=\"M114.34,-73.3129C114.34,-65.2895 114.34,-55.5475 114.34,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.84,-46.5288 114.34,-36.5288 110.84,-46.5289 117.84,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model so we can get a view of what it looks like\n",
    "# Note we'll do this in each training iteration later, but this'll keep the output tidy!\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "model, LossHistory = compile_model()\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "Train and use validation data to see if we're training effectively!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print X_train[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************\n",
      "\n",
      "Starting training iteration 1 with learning rate 0.03\n",
      "\n",
      "Train on 20181 samples, validate on 2243 samples\n",
      "Epoch 1/5\n",
      "20181/20181 [==============================] - 406s - loss: 2.4686 - acc: 0.1885 - val_loss: 2.2903 - val_acc: 0.1155\n",
      "Epoch 2/5\n",
      "20181/20181 [==============================] - 386s - loss: 1.9157 - acc: 0.3514 - val_loss: 2.2811 - val_acc: 0.2051\n",
      "Epoch 3/5\n",
      "20181/20181 [==============================] - 418s - loss: 1.6975 - acc: 0.4591 - val_loss: 2.3137 - val_acc: 0.1645\n",
      "Epoch 4/5\n",
      "20181/20181 [==============================] - 386s - loss: 1.3949 - acc: 0.5872 - val_loss: 2.7883 - val_acc: 0.1864\n",
      "Epoch 5/5\n",
      "20181/20181 [==============================] - 382s - loss: 1.0543 - acc: 0.7178 - val_loss: 3.0622 - val_acc: 0.2287\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAADhCAYAAAAjxHmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10efca410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 5 #10\n",
    "#learning_rate = [0.003, 0.01, 0.03, 0.1, 0.3]\n",
    "learningrate = 0.03\n",
    "\n",
    "for i in range(0,1):   # range(0,4) if doing multiple learning rates\n",
    "    #training_list, validation_list = split_drivers_into_train_and_validate(driver_ids)\n",
    "    print \"\\n**********************************\"\n",
    "    #print \"Driver train list: {}\".format(training_list)\n",
    "    #print \"Driver validation list: {}\".format(validation_list)\n",
    "    print \"\\nStarting training iteration {} with learning rate {}\\n\".format(i+1, learningrate)\n",
    "    model, LossHistory = compile_model(learningrate)\n",
    "    history = LossHistory()\n",
    "    #model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=num_epochs,\n",
    "    #          verbose=1, validation_data=(X_valid, y_valid), shuffle=True,\n",
    "    #          callbacks=[history]) \n",
    "    model.fit(X_train, y_train,            \n",
    "              batch_size=batch_size, \n",
    "              nb_epoch=num_epochs,\n",
    "              verbose=1,\n",
    "              validation_split = 0.10, shuffle=True,\n",
    "              callbacks=[history])\n",
    "    # validation_data=(X_train[validation_list], y_train[validation_list]),\n",
    "    graph_training_loss_history(history.losses)\n",
    "    #print('Score log_loss: ', get_log_loss_score(model, X_valid, y_valid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W_constraint': None, 'b_constraint': None, 'name': 'convolution2d_17', 'activity_regularizer': None, 'trainable': True, 'dim_ordering': 'th', 'nb_col': 3, 'subsample': (1, 1), 'init': 'glorot_uniform', 'bias': True, 'nb_filter': 8, 'activation': 'relu', 'input_dtype': 'float32', 'batch_input_shape': (None, 1, 224, 224), 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'nb_row': 3, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'border_mode': 'valid'}\n",
      "[array([[[[  1.33688718e-01,  -2.77976424e-01,  -9.07466486e-02],\n",
      "         [  9.79379416e-02,  -5.26607186e-02,  -1.97369486e-01],\n",
      "         [ -1.15320101e-01,  -7.50136375e-02,   1.89400211e-01]]],\n",
      "\n",
      "\n",
      "       [[[  6.19873777e-02,  -5.57135604e-02,   5.90566844e-02],\n",
      "         [  2.44567674e-02,   3.31708416e-02,   8.00936446e-02],\n",
      "         [ -2.28149727e-01,  -1.67146504e-01,  -2.38055095e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.01819761e-01,  -1.86408967e-01,  -2.35842302e-01],\n",
      "         [ -1.65169820e-01,   2.58689880e-01,   8.32898766e-02],\n",
      "         [  1.27312705e-01,  -5.24890162e-02,   3.14173460e-01]]],\n",
      "\n",
      "\n",
      "       [[[  5.16830608e-02,  -9.39658806e-02,  -1.59936115e-01],\n",
      "         [  1.28032044e-01,  -2.07185656e-01,  -1.97359189e-01],\n",
      "         [ -1.54701799e-01,  -1.02444626e-01,   1.06340006e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -5.12825996e-02,  -4.26139683e-02,  -1.99513063e-01],\n",
      "         [  4.34936723e-03,  -2.58783519e-01,  -2.10823312e-01],\n",
      "         [ -1.89099878e-01,  -8.97373655e-04,   5.56419492e-02]]],\n",
      "\n",
      "\n",
      "       [[[  3.73791099e-01,   2.06964120e-01,  -3.12182069e-01],\n",
      "         [  8.07768345e-01,   6.35707796e-01,  -9.88395885e-02],\n",
      "         [  4.62610334e-01,   2.40220726e-01,  -1.43325937e+00]]],\n",
      "\n",
      "\n",
      "       [[[ -6.85990462e-03,   4.52261884e-03,   2.21301660e-01],\n",
      "         [  1.54908508e-01,   2.85187095e-01,  -4.90720272e-01],\n",
      "         [  4.56220567e-01,   6.36999905e-02,  -6.14167154e-01]]],\n",
      "\n",
      "\n",
      "       [[[  3.94138545e-01,   5.90687245e-02,   1.39519051e-01],\n",
      "         [ -1.00093722e-01,  -2.19797462e-01,   7.89705664e-03],\n",
      "         [ -3.16246450e-01,  -5.27631529e-02,   1.39350638e-01]]]], dtype=float32), array([ -6.37751669e-02,  -5.44483289e-02,  -4.57735136e-02,\n",
      "        -2.16995589e-02,  -5.73712205e-05,  -3.41093957e-01,\n",
      "        -4.58316319e-02,  -2.85667665e-02], dtype=float32)]\n",
      "{'name': 'maxpooling2d_17', 'trainable': True, 'dim_ordering': 'th', 'pool_size': (2, 2), 'strides': (2, 2), 'border_mode': 'valid'}\n",
      "[]\n",
      "{'p': 0.25, 'trainable': True, 'name': 'dropout_25'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'convolution2d_18', 'activity_regularizer': None, 'trainable': True, 'dim_ordering': 'th', 'nb_col': 3, 'subsample': (1, 1), 'init': 'glorot_uniform', 'bias': True, 'nb_filter': 8, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'nb_row': 3, 'activation': 'linear', 'border_mode': 'valid'}\n",
      "[array([[[[ -1.36487437e-02,   1.09655470e-01,   1.03192084e-01],\n",
      "         [  1.52980164e-01,   1.61233664e-01,  -5.65520152e-02],\n",
      "         [  1.18662491e-01,  -1.24232307e-01,  -9.06696096e-02]],\n",
      "\n",
      "        [[  3.71930674e-02,  -1.83488190e-01,   4.58632372e-02],\n",
      "         [ -1.96204051e-01,   1.24706119e-01,   7.25887567e-02],\n",
      "         [  7.06174448e-02,   2.58530211e-02,  -1.18101478e-01]],\n",
      "\n",
      "        [[  1.36091337e-01,  -3.41246440e-03,  -7.89272189e-02],\n",
      "         [  1.86211914e-02,  -1.74763292e-01,   9.40284654e-02],\n",
      "         [ -1.57206550e-01,  -1.49788126e-01,  -1.39375165e-01]],\n",
      "\n",
      "        [[ -1.04610339e-01,  -1.61671847e-01,  -9.74426419e-02],\n",
      "         [  9.39134881e-02,   7.08423555e-02,  -1.18497968e-01],\n",
      "         [ -1.86418802e-01,   1.33269243e-02,   7.61440322e-02]],\n",
      "\n",
      "        [[  1.02879338e-01,  -1.73048317e-01,  -1.32702395e-01],\n",
      "         [  1.46818295e-01,  -1.27013743e-01,   1.92440674e-01],\n",
      "         [ -2.58653723e-02,   4.03247215e-03,  -9.00593773e-02]],\n",
      "\n",
      "        [[  4.02951658e-01,   1.19426198e-01,   3.55493993e-01],\n",
      "         [  7.17950881e-01,   7.26806641e-01,   3.64418775e-02],\n",
      "         [  5.62460661e-01,   1.16065122e-01,   2.42070537e-02]],\n",
      "\n",
      "        [[  1.22514710e-01,   4.31899950e-02,   2.17670381e-01],\n",
      "         [ -4.79271486e-02,  -1.06771560e-02,   2.84977973e-01],\n",
      "         [  3.09024334e-01,  -1.57079156e-02,   1.25609577e-01]],\n",
      "\n",
      "        [[  1.19533248e-01,   1.73034608e-01,   1.83826536e-01],\n",
      "         [ -4.15178910e-02,  -9.86355618e-02,   1.35379091e-01],\n",
      "         [  1.68780565e-01,   1.09911881e-01,   1.15537956e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.44494638e-01,  -1.24010578e-04,  -1.18127592e-01],\n",
      "         [ -8.55803117e-03,  -2.01481134e-01,  -1.69883192e-01],\n",
      "         [  2.09147744e-02,   4.91168424e-02,   1.27498507e-01]],\n",
      "\n",
      "        [[ -6.89273924e-02,   1.85974419e-01,   1.41447738e-01],\n",
      "         [ -1.17087169e-02,   8.84030014e-02,  -3.50841954e-02],\n",
      "         [ -1.41862392e-01,  -1.56500995e-01,  -5.76400124e-02]],\n",
      "\n",
      "        [[  1.16244428e-01,   2.48305202e-01,   1.42509341e-01],\n",
      "         [  1.17927445e-02,   1.89472392e-01,  -2.86953896e-02],\n",
      "         [  1.42004058e-01,  -8.98626596e-02,  -3.21127437e-02]],\n",
      "\n",
      "        [[ -7.58117065e-02,   4.42377292e-02,  -3.61072421e-02],\n",
      "         [  1.18756490e-02,   1.98977098e-01,  -1.00469530e-01],\n",
      "         [ -7.47464746e-02,  -2.08136626e-02,  -3.83943878e-02]],\n",
      "\n",
      "        [[  3.64931338e-02,  -1.59302384e-01,  -2.40446236e-02],\n",
      "         [ -5.77998273e-02,   5.51390015e-02,  -7.51928613e-02],\n",
      "         [  6.09982871e-02,  -1.36237651e-01,   1.79539874e-01]],\n",
      "\n",
      "        [[ -3.30469981e-02,   4.75487590e-01,   4.01306689e-01],\n",
      "         [  6.54041171e-01,   5.83188891e-01,   3.60365540e-01],\n",
      "         [  3.80295485e-01,   5.44191241e-01,   3.15828860e-01]],\n",
      "\n",
      "        [[  1.70230642e-01,   9.17706117e-02,  -4.61623296e-02],\n",
      "         [ -1.68349981e-01,   3.36216033e-01,   1.59275129e-01],\n",
      "         [  2.41007224e-01,  -8.54470581e-02,   1.41934544e-01]],\n",
      "\n",
      "        [[ -9.93364975e-02,  -8.18897337e-02,  -1.95382208e-01],\n",
      "         [ -1.85874738e-02,   9.41141024e-02,  -1.79575965e-01],\n",
      "         [  2.02051789e-01,   1.96635306e-01,  -2.23760195e-02]]],\n",
      "\n",
      "\n",
      "       [[[  1.32908180e-01,  -9.31509286e-02,   1.33026674e-01],\n",
      "         [ -1.01779334e-01,  -2.09081005e-02,   1.40013233e-01],\n",
      "         [ -1.54587314e-01,  -9.13657621e-02,   8.48745704e-02]],\n",
      "\n",
      "        [[ -8.25968161e-02,  -8.04570615e-02,  -4.01959904e-02],\n",
      "         [ -1.00240484e-01,   1.14875086e-01,  -1.02519676e-01],\n",
      "         [  1.77618265e-01,  -1.89617813e-01,  -1.14878066e-01]],\n",
      "\n",
      "        [[ -1.68256819e-01,  -1.44350886e-01,   1.16077535e-01],\n",
      "         [  1.52839303e-01,  -1.71783701e-01,   1.67905495e-01],\n",
      "         [  2.14638724e-03,   6.47630170e-02,   1.80065513e-01]],\n",
      "\n",
      "        [[  1.83428507e-02,   1.79372236e-01,  -1.67954728e-01],\n",
      "         [ -1.59042373e-01,   1.37103230e-01,   1.18685760e-01],\n",
      "         [ -1.81291521e-01,  -3.77822295e-02,  -6.52361512e-02]],\n",
      "\n",
      "        [[ -4.72783148e-02,   2.00174958e-01,  -1.81585327e-01],\n",
      "         [  4.92487289e-03,   1.18256137e-02,   9.06599015e-02],\n",
      "         [ -1.89824596e-01,   1.61085621e-01,   1.80397362e-01]],\n",
      "\n",
      "        [[  2.39977136e-01,   4.93612319e-01,   4.87000316e-01],\n",
      "         [  1.84453443e-01,   5.25075421e-02,   5.06718338e-01],\n",
      "         [  4.33258787e-02,   1.83355838e-01,  -1.66671304e-03]],\n",
      "\n",
      "        [[  1.84757456e-01,   2.52234280e-01,   4.24537025e-02],\n",
      "         [  1.21944010e-01,  -6.47774041e-02,   2.66391546e-01],\n",
      "         [  2.21550018e-01,   1.24526232e-01,  -1.61909219e-02]],\n",
      "\n",
      "        [[  2.27947935e-01,   6.87223747e-02,  -2.54815761e-02],\n",
      "         [ -1.39179766e-01,   8.50887522e-02,   2.39050925e-01],\n",
      "         [ -1.38688415e-01,   5.60164340e-02,   3.97257879e-02]]],\n",
      "\n",
      "\n",
      "       [[[  4.75250091e-03,  -1.07680373e-01,   6.14730418e-02],\n",
      "         [ -6.25402201e-03,   1.08258992e-01,  -1.84632048e-01],\n",
      "         [  7.38474429e-02,  -9.00703222e-02,   1.32662416e-01]],\n",
      "\n",
      "        [[  1.73334181e-01,   1.28265381e-01,  -3.93888308e-03],\n",
      "         [ -9.27312523e-02,  -8.71784091e-02,   1.71013355e-01],\n",
      "         [ -4.50435653e-02,  -1.67751849e-01,   1.75422966e-01]],\n",
      "\n",
      "        [[ -1.53300241e-01,  -1.63789108e-01,  -1.69172719e-01],\n",
      "         [ -1.37075158e-02,  -9.70405564e-02,   7.96967372e-02],\n",
      "         [  7.10926354e-02,  -1.44702988e-02,  -1.98440194e-01]],\n",
      "\n",
      "        [[  3.81355062e-02,   1.95954546e-01,   8.08876157e-02],\n",
      "         [  1.48566499e-01,   1.81758821e-01,   2.32401602e-02],\n",
      "         [ -8.61576647e-02,  -1.09070413e-01,   9.55598652e-02]],\n",
      "\n",
      "        [[ -7.21823573e-02,  -1.11317761e-01,  -2.16542371e-02],\n",
      "         [  1.29048392e-01,   1.00922547e-01,  -3.33971120e-02],\n",
      "         [  1.84393719e-01,   7.85240233e-02,   1.43834680e-01]],\n",
      "\n",
      "        [[  3.56441408e-01,   1.95071012e-01,  -5.01999669e-02],\n",
      "         [  1.53653398e-01,   6.24699034e-02,  -1.00689731e-03],\n",
      "         [  3.37248743e-01,   3.78990829e-01,  -1.53400719e-01]],\n",
      "\n",
      "        [[  3.70730832e-02,   1.32218167e-01,   1.58283740e-01],\n",
      "         [  2.34727144e-01,   1.25818521e-01,  -1.09752946e-01],\n",
      "         [  1.24799527e-01,   8.77618119e-02,   2.08772331e-01]],\n",
      "\n",
      "        [[  1.27904639e-01,  -1.59960434e-01,   7.62785375e-02],\n",
      "         [  1.52738720e-01,   2.01146439e-01,   1.73890293e-01],\n",
      "         [  6.50732443e-02,  -1.52699038e-01,  -7.54653364e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -1.59342408e-01,  -5.29962592e-02,   2.97204126e-02],\n",
      "         [ -2.02485263e-01,  -8.94944519e-02,   5.75470552e-02],\n",
      "         [ -7.97694251e-02,   5.06698415e-02,  -9.44569036e-02]],\n",
      "\n",
      "        [[ -1.81162044e-01,   1.81954116e-01,   1.26839086e-01],\n",
      "         [  8.71330425e-02,  -1.72353685e-01,  -1.85737535e-01],\n",
      "         [  8.15045163e-02,   4.49539013e-02,  -8.45664442e-02]],\n",
      "\n",
      "        [[  3.80527824e-02,  -1.27213104e-02,  -4.03865427e-02],\n",
      "         [ -4.39093299e-02,  -6.58390149e-02,  -1.18355602e-01],\n",
      "         [  1.78068995e-01,   1.17665775e-01,  -7.51288608e-02]],\n",
      "\n",
      "        [[  1.46386072e-01,  -7.42226914e-02,  -5.60761094e-02],\n",
      "         [ -1.12371318e-01,  -4.33624052e-02,  -1.81106061e-01],\n",
      "         [ -2.00693589e-02,  -1.42571153e-02,  -1.97247267e-01]],\n",
      "\n",
      "        [[ -2.97477432e-02,   7.10533038e-02,  -4.85371575e-02],\n",
      "         [  6.40586093e-02,  -1.03477344e-01,   1.29575819e-01],\n",
      "         [ -7.04609305e-02,  -1.77852735e-01,   1.78988814e-01]],\n",
      "\n",
      "        [[  5.71486205e-02,  -1.39541790e-01,   2.07105294e-01],\n",
      "         [  2.94948667e-01,   2.97291905e-01,   3.33399713e-01],\n",
      "         [  2.78725564e-01,   8.17461908e-02,   3.83031577e-01]],\n",
      "\n",
      "        [[ -5.47981150e-02,  -9.23042819e-02,  -1.72927499e-01],\n",
      "         [ -1.52700320e-01,   5.80952652e-02,  -2.91817654e-02],\n",
      "         [ -1.90183982e-01,  -1.80249050e-01,  -1.47632867e-01]],\n",
      "\n",
      "        [[  1.31918207e-01,   1.29232451e-01,  -1.35924175e-01],\n",
      "         [ -1.47702828e-01,  -7.11384788e-02,  -1.63382351e-01],\n",
      "         [ -1.38155548e-02,  -1.71609268e-01,  -1.96882769e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.85936615e-02,  -1.05792239e-01,   8.97030905e-02],\n",
      "         [ -2.01541364e-01,   1.32051017e-02,  -1.76160112e-01],\n",
      "         [  9.70792174e-02,  -5.63744716e-02,  -5.19790389e-02]],\n",
      "\n",
      "        [[  1.55914590e-01,  -1.12814263e-01,   9.25368816e-02],\n",
      "         [  1.87571775e-02,  -1.87740430e-01,  -1.26530647e-01],\n",
      "         [  1.40061928e-02,   1.48190521e-02,   4.83515672e-02]],\n",
      "\n",
      "        [[  2.10565135e-01,   1.76306352e-01,   2.28888944e-01],\n",
      "         [ -1.17098600e-01,   1.23953119e-01,   8.20777118e-02],\n",
      "         [  1.59961730e-01,   1.93269923e-02,   9.60824788e-02]],\n",
      "\n",
      "        [[ -9.63164270e-02,  -1.29254162e-01,   1.66185856e-01],\n",
      "         [  6.86585233e-02,   3.71238217e-02,  -1.83145210e-01],\n",
      "         [  4.45430949e-02,   1.18784465e-01,  -6.03927895e-02]],\n",
      "\n",
      "        [[  2.91163828e-02,   1.11760639e-01,  -1.69225782e-01],\n",
      "         [  5.65259382e-02,  -1.00751743e-02,  -4.30657938e-02],\n",
      "         [  8.50428361e-03,  -9.96505623e-05,   9.70805734e-02]],\n",
      "\n",
      "        [[  5.06395936e-01,   5.73253512e-01,   5.55266380e-01],\n",
      "         [  4.98515248e-01,   8.90041351e-01,   7.78741896e-01],\n",
      "         [  6.34556174e-01,   2.16464087e-01,   3.27924311e-01]],\n",
      "\n",
      "        [[ -1.25915647e-01,   1.58160761e-01,   3.60890239e-01],\n",
      "         [  9.41473022e-02,   2.01670796e-01,   1.31018594e-01],\n",
      "         [  2.36055832e-02,  -4.03277911e-02,   2.37953752e-01]],\n",
      "\n",
      "        [[ -3.63776051e-02,  -1.61243870e-03,  -2.63851583e-02],\n",
      "         [  1.73790500e-01,  -1.11800246e-01,  -4.95803505e-02],\n",
      "         [ -6.64988235e-02,   2.87697077e-01,   1.11810252e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.11319125e-02,  -1.17253490e-01,   2.37899888e-02],\n",
      "         [ -2.01184690e-01,  -6.63963109e-02,  -1.15210138e-01],\n",
      "         [  4.26792800e-02,   1.92980424e-01,   2.29580477e-02]],\n",
      "\n",
      "        [[  8.57230574e-02,  -1.21056408e-01,  -3.36999781e-02],\n",
      "         [ -1.00303933e-01,  -1.63821772e-01,  -1.12749390e-01],\n",
      "         [  9.52846557e-03,  -1.76556930e-01,  -3.08704525e-02]],\n",
      "\n",
      "        [[  1.05078168e-01,   1.25472099e-01,  -6.53581694e-02],\n",
      "         [ -1.58638507e-01,  -2.48032603e-02,  -1.93487659e-01],\n",
      "         [  1.53079331e-01,  -2.65169293e-02,  -9.92019400e-02]],\n",
      "\n",
      "        [[ -1.15051389e-01,  -1.38717771e-01,  -6.39473423e-02],\n",
      "         [ -1.08612761e-01,   1.67981058e-01,   8.91800150e-02],\n",
      "         [ -1.57970369e-01,  -9.66726840e-02,   1.57619536e-01]],\n",
      "\n",
      "        [[  1.15924485e-01,  -5.00904396e-02,   4.17073630e-02],\n",
      "         [  1.73682719e-01,  -8.59370679e-02,  -9.41120163e-02],\n",
      "         [  6.54399917e-02,   8.43773112e-02,   7.70858601e-02]],\n",
      "\n",
      "        [[  4.11195248e-01,  -1.11665636e-01,  -1.41194150e-01],\n",
      "         [  4.74762112e-01,   8.79674554e-02,   3.54386754e-02],\n",
      "         [  2.06319958e-01,   9.90594253e-02,  -7.75663853e-02]],\n",
      "\n",
      "        [[  2.52654344e-01,  -3.71211208e-02,   2.11604565e-01],\n",
      "         [  2.45983049e-01,   2.37332165e-01,  -6.43730862e-03],\n",
      "         [  2.62154154e-02,  -1.37048453e-01,  -8.39284733e-02]],\n",
      "\n",
      "        [[  8.74003917e-02,   8.97977799e-02,   1.28262401e-01],\n",
      "         [ -1.53241858e-01,  -1.74254864e-01,   4.65134233e-02],\n",
      "         [  4.46530432e-02,  -1.40371993e-01,   9.56734195e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -1.38221100e-01,   1.49109408e-01,  -9.33848321e-03],\n",
      "         [  1.80624396e-01,   3.30945640e-03,  -1.92648053e-01],\n",
      "         [ -3.57363708e-02,   1.53287068e-01,   6.17669746e-02]],\n",
      "\n",
      "        [[ -6.41532391e-02,   1.80060074e-01,   1.68382481e-01],\n",
      "         [  2.00113162e-01,  -1.05690166e-01,  -4.55282163e-03],\n",
      "         [ -1.52821779e-01,   2.75420137e-02,  -2.47678533e-02]],\n",
      "\n",
      "        [[  1.45370394e-01,   2.07079217e-01,  -4.05660346e-02],\n",
      "         [ -1.05894439e-01,  -1.29444361e-01,   8.30507055e-02],\n",
      "         [ -1.74130231e-01,  -1.54493853e-01,   1.63635492e-01]],\n",
      "\n",
      "        [[ -1.69971406e-01,   2.61489023e-02,   1.98839054e-01],\n",
      "         [  5.53440377e-02,   5.99228963e-02,  -2.03516632e-01],\n",
      "         [ -1.21234819e-01,  -1.30429899e-03,  -1.41599581e-01]],\n",
      "\n",
      "        [[ -1.50569871e-01,  -7.42657781e-02,   1.01220638e-01],\n",
      "         [  9.01915804e-02,   1.17980912e-01,  -2.95682307e-02],\n",
      "         [ -1.97536945e-01,  -9.64749902e-02,   5.30996732e-02]],\n",
      "\n",
      "        [[ -2.00973041e-02,   1.60897583e-01,   1.55539960e-01],\n",
      "         [ -1.85799599e-01,   5.27445190e-02,  -1.10544506e-02],\n",
      "         [ -1.64905190e-01,  -9.69636738e-02,  -7.50462115e-02]],\n",
      "\n",
      "        [[  6.29970059e-02,  -6.58132806e-02,   1.65474117e-01],\n",
      "         [  1.45449176e-01,   3.45334187e-02,  -1.13961071e-01],\n",
      "         [ -2.94197593e-02,   1.89831927e-01,   3.80979143e-02]],\n",
      "\n",
      "        [[  1.26601353e-01,   1.90304413e-01,  -1.22897118e-01],\n",
      "         [ -3.79555561e-02,   7.08862096e-02,  -9.91395935e-02],\n",
      "         [ -5.80414757e-02,   1.69584975e-01,  -1.36110680e-02]]]], dtype=float32), array([-0.0715967 , -0.06409337, -0.08076873, -0.01986024, -0.01512067,\n",
      "       -0.13483742, -0.00806643,  0.00232845], dtype=float32)]\n",
      "{'activation': 'relu', 'trainable': True, 'name': 'activation_25'}\n",
      "[]\n",
      "{'name': 'maxpooling2d_18', 'trainable': True, 'dim_ordering': 'th', 'pool_size': (2, 2), 'strides': (2, 2), 'border_mode': 'valid'}\n",
      "[]\n",
      "{'p': 0.25, 'trainable': True, 'name': 'dropout_26'}\n",
      "[]\n",
      "{'trainable': True, 'name': 'flatten_9'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'dense_17', 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'activation': 'linear', 'input_dim': None, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'output_dim': 128}\n",
      "[array([[ 0.00488001,  0.00955289,  0.01788561, ..., -0.00992373,\n",
      "         0.03156997, -0.00490643],\n",
      "       [ 0.01374238,  0.00715044, -0.00195868, ...,  0.01898352,\n",
      "         0.03283659, -0.00420416],\n",
      "       [ 0.00646908, -0.01461038, -0.01523622, ..., -0.01579265,\n",
      "         0.0316367 ,  0.00509186],\n",
      "       ..., \n",
      "       [ 0.006164  ,  0.01240457, -0.0086465 , ..., -0.00333271,\n",
      "         0.00249009, -0.01266723],\n",
      "       [-0.01334981, -0.00967446,  0.005194  , ...,  0.00449865,\n",
      "         0.00854161,  0.00878783],\n",
      "       [ 0.01206938,  0.01506422,  0.00314505, ..., -0.01507708,\n",
      "        -0.00776077,  0.00682224]], dtype=float32), array([  6.93954935e-04,  -1.93433929e-03,  -9.55662457e-04,\n",
      "         4.52252105e-03,   5.35934232e-05,  -3.08797666e-04,\n",
      "         3.98448063e-03,  -1.05323270e-03,   4.99816053e-03,\n",
      "        -1.63171382e-03,   3.11778951e-03,  -1.45517418e-03,\n",
      "        -1.66520244e-03,  -1.01775187e-03,  -5.53105318e-04,\n",
      "         1.39445690e-02,   1.86165480e-03,  -1.90333510e-03,\n",
      "         5.61220199e-03,   7.46132387e-03,   2.95344071e-04,\n",
      "        -2.39770068e-03,  -5.43763686e-04,   3.17293871e-03,\n",
      "        -1.08263560e-03,  -2.05867272e-03,   2.44583888e-03,\n",
      "         4.17976500e-03,  -1.13932777e-03,   2.72606174e-03,\n",
      "        -1.90900161e-03,  -1.60249718e-03,   1.89718721e-03,\n",
      "        -1.75394851e-03,  -1.29852351e-03,  -7.88865611e-04,\n",
      "         7.50151090e-03,   3.75012401e-03,  -4.67016653e-04,\n",
      "        -7.36218295e-04,   2.63378560e-03,   1.59580063e-03,\n",
      "        -1.33258081e-03,  -1.22816302e-03,   1.45955081e-03,\n",
      "         1.29944226e-03,  -2.51640915e-04,   3.66399065e-03,\n",
      "        -1.03983714e-03,   4.46384074e-03,  -1.86254561e-03,\n",
      "        -2.44706840e-04,  -7.22121680e-04,  -4.31552871e-05,\n",
      "        -2.42123636e-03,  -8.32245045e-04,  -1.33564149e-03,\n",
      "         3.81548423e-04,   3.48004652e-03,   3.34379403e-03,\n",
      "         1.98283070e-03,  -3.25731607e-03,  -3.97065684e-04,\n",
      "        -1.90028152e-03,   4.16238140e-03,   2.33657286e-03,\n",
      "        -3.90693487e-04,   3.52925691e-03,  -2.96148844e-03,\n",
      "        -1.67541369e-03,   9.19891754e-04,  -2.35606078e-03,\n",
      "         8.23340099e-03,  -2.27231882e-03,  -1.23830780e-03,\n",
      "        -1.71404099e-03,  -1.58423456e-04,   2.60461122e-04,\n",
      "        -1.18149491e-03,  -2.26768269e-03,  -1.70071051e-03,\n",
      "        -3.00301035e-04,   6.48695556e-03,  -4.21185687e-04,\n",
      "         7.67146470e-03,  -1.00530114e-03,  -1.77350221e-03,\n",
      "         6.40955754e-03,  -2.07989942e-03,  -1.98791362e-03,\n",
      "        -4.78578950e-05,   3.26172402e-03,  -2.66881124e-03,\n",
      "        -9.94854723e-04,   9.40046459e-03,   3.54834716e-04,\n",
      "        -1.06053089e-03,  -1.38573407e-03,  -1.19621016e-03,\n",
      "        -1.30102198e-04,  -2.60547531e-04,   1.09514117e-03,\n",
      "         2.89617223e-03,   4.44730715e-04,  -7.42446049e-04,\n",
      "         6.52184663e-03,  -2.36017164e-03,   5.61783731e-04,\n",
      "        -1.33731883e-04,   1.54135725e-03,  -1.51895510e-03,\n",
      "        -5.54319471e-04,  -5.81631321e-04,  -2.47082463e-03,\n",
      "        -2.64962673e-05,  -1.11739419e-03,  -3.97633936e-04,\n",
      "         2.07578647e-03,  -1.84225792e-03,   8.51682294e-03,\n",
      "        -1.66082219e-03,  -2.37319618e-03,   1.63720995e-02,\n",
      "         2.19021132e-03,   6.82529854e-03,   1.52732432e-02,\n",
      "         1.10472217e-02,  -1.00641162e-03], dtype=float32)]\n",
      "{'activation': 'relu', 'trainable': True, 'name': 'activation_26'}\n",
      "[]\n",
      "{'p': 0.5, 'trainable': True, 'name': 'dropout_27'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'dense_18', 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'activation': 'linear', 'input_dim': None, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'output_dim': 10}\n",
      "[array([[  1.24719227e-03,  -1.61669304e-04,  -1.38739022e-04, ...,\n",
      "         -1.04217870e-04,  -9.28662630e-05,  -1.54336376e-04],\n",
      "       [  3.27100754e-02,  -6.71173586e-03,   1.18346792e-03, ...,\n",
      "         -7.13409856e-03,   1.13613028e-02,   4.57291538e-03],\n",
      "       [ -2.73530781e-02,  -1.78029370e-02,   7.74551257e-02, ...,\n",
      "         -1.99756734e-02,   1.22534148e-02,   1.06081646e-03],\n",
      "       ..., \n",
      "       [  1.83877330e-02,  -4.18752283e-02,  -1.47268949e-02, ...,\n",
      "         -3.29742022e-02,  -2.95872632e-02,  -7.99600128e-03],\n",
      "       [ -1.45605467e-02,  -1.45542473e-02,   3.20625603e-02, ...,\n",
      "         -4.20723520e-02,   8.24788660e-02,  -3.47214565e-02],\n",
      "       [ -4.08479129e-04,  -1.03759594e-04,  -4.79918468e-04, ...,\n",
      "         -1.27196981e-04,   1.84634072e-03,  -3.59777448e-04]], dtype=float32), array([ 0.00405992, -0.0055772 ,  0.0110706 ,  0.00322192, -0.00101371,\n",
      "       -0.01372817,  0.00168722, -0.00764493, -0.00010582,  0.00803016], dtype=float32)]\n",
      "{'activation': 'softmax', 'trainable': True, 'name': 'activation_27'}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print layer.get_config()\n",
    "    print layer.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./model/saved_weights_converged.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Visualise what the CNN has learnt\n",
    "Inspired by https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py and https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'convolution2d_39 '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-f3c6f9e3b7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'convolution2d_39 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlayer_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Number of filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'convolution2d_39 '"
     ]
    }
   ],
   "source": [
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'convolution2d_39 '\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_output = layer_dict[layer_name].output\n",
    "\n",
    "# Number of filters\n",
    "n = 8\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "imsave('stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "def load_test_images(test_images_dir):\n",
    "    total = 0\n",
    "    images = []\n",
    "    image_ids = []\n",
    "    test_image_list = os.listdir(test_images_dir)\n",
    "    num_test_images = len(test_image_list)\n",
    "    for i in range(0,num_test_images):\n",
    "        filename = test_images_dir + test_image_list[i]\n",
    "        image = cv2.imread(filename, 0).transpose()  # Is the color_type needed here as these are pre-processed images??\n",
    "        images.append(image)  \n",
    "        image_ids.append(test_image_list[i])\n",
    "        total += 1\n",
    "        if total % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nProcesses {} rows.\".format(total)\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    images = images.reshape(images.shape[0], color_type, image_width, image_height)\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    return images, np.array(image_ids)\n",
    "\n",
    "#test_image_batches = split_test_data(test_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data, batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print predictions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def create_submission(predictions, test_ids, test_info):\n",
    "    result = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result.loc[:, 'img'] = pd.Series(test_ids, index=result.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('submission'):\n",
    "        os.mkdir('submission')\n",
    "    suffix = test_info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('submission', 'submission_' + suffix + '.csv')\n",
    "    result.to_csv(sub_file, index=False)\n",
    "\n",
    "#+ str(score) \\\n",
    "test_info = 'loss_' \\\n",
    "                + '_h_' + str(image_height) \\\n",
    "                + '_w_' + str(image_width) \\\n",
    "                + '_ep_' + str(num_epochs)\n",
    "create_submission(predictions, test_ids, test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###VGG16 model\n",
    "From https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "Also see:\n",
    "http://blog.christianperone.com/2016/01/convolutional-hypercolumns-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg16(num_classes, weights_path=None):\n",
    "    \n",
    "    # Create callback for history report\n",
    "    from keras.callbacks import Callback\n",
    "    class LossHistory(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        print \"Loading weights from {}\".format(weights_path)\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "    # Now replace the top layer with one for our own purposes\n",
    "    model.layers.pop()\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    #TODO - Rework model based on \n",
    "    return model, LossHistory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
