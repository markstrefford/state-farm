{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the State Farm image data\n",
    "\n",
    "This notebook provides analysis of the provided State Farm data, using Theano and Keras to build the NN.\n",
    "\n",
    "### Prerequisites\n",
    "Please see the Readme.md file for pre-requisite Python libraries\n",
    "\n",
    "Note that the data is available from Kaggle here:  \n",
    "https://www.kaggle.com/c/state-farm-distracted-driver-detection/data\n",
    "\n",
    "Please extract the data set into the /imgs folder within this code.  For example ./state-farm/imgs/ \n",
    "\n",
    "If this is the 1st run after downloading the data, then please set create_repository to True below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "First, let's import what we need and set up environment variables, etc.\n",
    "\n",
    "If the following commands error with the message \"Exception: Can't change the value of this config parameter after initialization!\" then please re-start ipython with the following command:\n",
    "\n",
    "THEANO_FLAGS=device=gpu,floatX=float32 ipython notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device gpu failed:\n",
      "initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_CUDA_ERROR. numdev=1\n",
      "\n",
      "ERROR:theano.sandbox.cuda:ERROR: Not using GPU. Initialisation of device gpu failed:\n",
      "initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_CUDA_ERROR. numdev=1\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Can't change the value of this config parameter after initialization!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e246e7cb99d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/configparser.pyc\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, cls, val)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_override\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             raise Exception(\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0;34m\"Can't change the value of this config parameter \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \"after initialization!\")\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# print \"SETTING PARAM\", self.fullname,(cls), val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Can't change the value of this config parameter after initialization!"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "theano.config.device = 'gpu'\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports of the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# These are the locations of the images provided by Kaggle\n",
    "# Root Dir is needed for Python, but not for create lmdb shell script later... (we need it there too!)\n",
    "image_root_dir = './imgs/'\n",
    "train_image_source_dir = \"./train/\"\n",
    "test_image_source_dir = \"./test/\"\n",
    "driver_image_list = \"./driver_imgs_list.csv\"\n",
    "\n",
    "# These are the locations of the images that we will work with \n",
    "# Note that as we're continually mix up training and validation drivers/images, \n",
    "# then we will store images in one directory and use code to determine whether to train or validate\n",
    "train_images_dir = \"./images/train/\"\n",
    "#validation_images_dir = \"./images/validate/\" \n",
    "test_images_dir = \"./images/test/\"\n",
    "\n",
    "# Some more controls\n",
    "# color type: 1 - grey, 3 - rgb\n",
    "color_type = 1 \n",
    "image_width = 224 \n",
    "image_height = 224 \n",
    "\n",
    "create_repository = False    # True forces pre-processing images, set to True for the first run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start by pre-processing the images\n",
    "There are only 27 different drivers so in order to avoid overfitting, or testing using very similar data to training, we will split the data based on the driver into train and validation sets.\n",
    "\n",
    "Initially though, let's get the list of drivers, see how many images are available for each driver, and which classification they have been labelled with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data summary: \n",
      "  subject classname            img\n",
      "0    p002        c0  img_44733.jpg\n",
      "1    p002        c0  img_72999.jpg\n",
      "2    p002        c0  img_25094.jpg\n",
      "3    p002        c0  img_69092.jpg\n",
      "4    p002        c0  img_92629.jpg\n",
      "\n",
      "Testing data summary: \n",
      "['img_1.jpg', 'img_10.jpg', 'img_100.jpg', 'img_1000.jpg', 'img_100000.jpg', 'img_100001.jpg', 'img_100002.jpg', 'img_100003.jpg', 'img_100004.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Training set is in the provided csv file\n",
    "driver_list = pd.read_csv(driver_image_list)\n",
    "print \"Training data summary: \\n{}\".format(driver_list.head())\n",
    "\n",
    "test_image_list = os.listdir(image_root_dir + test_image_source_dir)\n",
    "print \"\\nTesting data summary: \\n{}\".format(test_image_list[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process images so that they are in an format more suited to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training images found 22424\n"
     ]
    }
   ],
   "source": [
    "def get_driver_images_and_classes(driver_list):\n",
    "    image_list = []\n",
    "    class_list = []\n",
    "    total = 0\n",
    "    for driver_row in [ drvr for drvr in driver_list.iterrows() ]:   # if drvr[1]['subject'] in filter \n",
    "        driver = driver_row[1]  # Drop the index created by the Pandas Dataframe\n",
    "        driver_class = int(driver['classname'][1:])  # Get integer to represent class (eg 'c0' is class '0')\n",
    "        image_list.append(driver['img'])\n",
    "        class_list.append(driver_class)\n",
    "        total += 1\n",
    "    print \"Total number of training images found {}\".format(total)\n",
    "    #Return a list of images and their classification\n",
    "    return np.array(image_list), np.array(class_list)\n",
    "\n",
    "# Create a training list of images and classes from the training set\n",
    "images, classes = get_driver_images_and_classes(driver_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Process the image, for now this is resize only\n",
    "# We'll handle colour/greyscale when we load as cv2 does this for us\n",
    "# TODO - Move directory creation to Python code to be OS independent\n",
    "\n",
    "def pre_process_image(image):\n",
    "    processed_img = cv2.resize(image, (image_width, image_height)) \n",
    "    return processed_img\n",
    "    \n",
    "def create_train_image_repository(images_dest_dir, images_list, class_list, color_type=1):\n",
    "    print \"create_image_repository(): Processing images into {}\".format(images_dest_dir)\n",
    "    copied = 0 \n",
    "    for f, c in zip(images_list, class_list):\n",
    "        dest_dir = images_dest_dir + str(c) + \"/\"\n",
    "        if os.path.exists(dest_dir) == False:\n",
    "            !mkdir $dest_dir\n",
    "        image_filename = image_root_dir + train_image_source_dir + '/c' + str(c) + '/' + f\n",
    "        if color_type == 1:\n",
    "            orig_img = cv2.imread(image_filename, 0)\n",
    "        elif color_type == 3:\n",
    "            orig_img = cv2.imread(image_filename)\n",
    "        processed_image = pre_process_image(orig_img)\n",
    "        cv2.imwrite(images_dest_dir + str(c) + \"/\" + f, processed_image)\n",
    "        copied += 1\n",
    "        if copied % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nCopied {} images...Done!\".format(copied)\n",
    "    return copied\n",
    "\n",
    "def create_test_image_repository(dest_dir, images_list, color_type=1):\n",
    "    print \"create_image_repository(): Processing images into {}\".format(dest_dir)\n",
    "    copied = 0 \n",
    "    for f in images_list:\n",
    "        if os.path.exists(dest_dir) == False:\n",
    "            !mkdir $dest_dir\n",
    "        image_filename = image_root_dir + test_image_source_dir + f\n",
    "        if color_type == 1:\n",
    "            orig_img = cv2.imread(image_filename, 0)\n",
    "        elif color_type == 3:\n",
    "            orig_img = cv2.imread(image_filename)\n",
    "        processed_image = pre_process_image(orig_img)\n",
    "        cv2.imwrite(dest_dir + f, processed_image)\n",
    "        copied += 1\n",
    "        if copied % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nCopied {} images...Done!\".format(copied)\n",
    "    return copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process images if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start by clearing out any old data (ignore failures here if the directory doesn't exist)\n",
    "# TODO - Move to Python code to be OS independent\n",
    "\n",
    "if create_repository:\n",
    "    print \"Deleting old repositories if they exist, this may take a while...\"\n",
    "    !rm -rf $train_images_dir\n",
    "    #!rm -rf $validation_images_dir\n",
    "    !rm -rf $test_images_dir\n",
    "\n",
    "    # Create directories\n",
    "    !mkdir -p $train_images_dir\n",
    "    #!mkdir -p $validation_images_dir\n",
    "    !mkdir -p $test_images_dir\n",
    "\n",
    "    create_test_image_repository(test_images_dir, test_image_list, color_type=color_type)\n",
    "    create_train_image_repository(train_images_dir, images, classes, color_type=color_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Currently unused\n",
    "def render_image(image_filename):\n",
    "    print \"render_image(): Rendering {}\".format(image_filename)\n",
    "    image = cv2.imread(image_filename, color_type_global)\n",
    "    plt.axis(\"off\")\n",
    "    #plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.imshow(image)\n",
    "    plt.show() \n",
    "    #print image.shape\n",
    "    #plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, validation and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the drivers into a training and validation set.  To ensure we don't have overfitting (the training set and the validation set contain the same or similar images) we will split on drivers, so a driver can only appear in training or validation but not both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 drivers: ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n"
     ]
    }
   ],
   "source": [
    "driver_ids = []\n",
    "for id, driver in driver_list.iterrows():\n",
    "    if driver['subject'] not in driver_ids:\n",
    "        driver_ids.append(driver['subject'])\n",
    "print \"Found {} drivers: {}\".format(len(driver_ids), driver_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and validation data tests (split = percentage to have in training set)\n",
    "and then create X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "def create_train_validation_data(driver_list, filter):\n",
    "    #sample = driver_list[driver_list.subject.isin(filter)].ix[:, 'classname':'img']\n",
    "    images = []\n",
    "    labels = []\n",
    "    total = 0\n",
    "    for driver_row in [ drvr for drvr in driver_list[driver_list.subject.isin(filter)].ix[:, 'classname':'img'].iterrows() ]:   # if drvr[1]['subject'] in filter \n",
    "        driver = driver_row[1]  # Drop the index created by the Pandas Dataframe\n",
    "        #print driver\n",
    "        label = int(driver['classname'][1:])\n",
    "        filename = train_images_dir + str(label) + \"/\" + driver['img']\n",
    "        if color_type == 1:\n",
    "            image = cv2.imread(filename, 0).transpose()  # Is the color_type needed here as these are pre-processed images??\n",
    "        elif color_type == 3:\n",
    "            image = cv2.imread(filename).transpose()     # Is the color_type needed here as these are pre-processed images??\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        total += 1\n",
    "        if total % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nProcessed {} rows.\".format(total)\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    images = images.reshape(images.shape[0], color_type, image_width, image_height)\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    labels = np.array(labels, dtype=np.uint8)\n",
    "    labels = np_utils.to_categorical(labels, 10)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_drivers_into_train_and_validate(driver_list, split = 1.0):\n",
    "    driver_valid_list = []\n",
    "    # Take a random sample of drivers into the training list\n",
    "    driver_train_list = np.random.choice(driver_list, int(len(driver_list)*split), replace = False)\n",
    "    # Take the remaining drivers into the validation list\n",
    "    driver_valid_list = [ driver for driver in driver_list if driver not in driver_train_list]\n",
    "    return driver_train_list, driver_valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p047' 'p061' 'p022' 'p035' 'p066' 'p075' 'p016' 'p081' 'p026' 'p024'\n",
      " 'p041' 'p015' 'p056' 'p049' 'p012' 'p064' 'p052' 'p021' 'p072' 'p014'\n",
      " 'p042' 'p051' 'p039' 'p050']\n",
      "['p002', 'p045']\n"
     ]
    }
   ],
   "source": [
    "training_list, validation_list = split_drivers_into_train_and_validate(driver_ids, split = 0.95)\n",
    "print training_list\n",
    "print validation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training/validation data:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Processed 20975 rows.\n",
      "Creating validation data:\n",
      ". . . . . . . . . . . . . . \n",
      "Processed 1449 rows.\n"
     ]
    }
   ],
   "source": [
    "print \"Creating training/validation data:\"\n",
    "X_train, y_train = create_train_validation_data(driver_list, training_list)\n",
    "print \"Creating validation data:\"\n",
    "X_valid, y_valid = create_train_validation_data(driver_list, validation_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the dimensions / shape of the training and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20975, 1, 224, 224)\n",
      "(20975, 10)\n",
      "(1449, 1, 224, 224)\n",
      "(1449, 10)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "#num_training_samples = X_train.shape[0]\n",
    "print X_valid.shape\n",
    "print y_valid.shape\n",
    "#num_validation_samples = X_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "def load_test_images(test_images_dir):\n",
    "    total = 0\n",
    "    images = []\n",
    "    image_ids = []\n",
    "    test_image_list = os.listdir(test_images_dir)\n",
    "    num_test_images = len(test_image_list)\n",
    "    for i in range(0,num_test_images):\n",
    "        filename = test_images_dir + test_image_list[i]\n",
    "        image = cv2.imread(filename, 0).transpose()  # Is the color_type needed here as these are pre-processed images??\n",
    "        images.append(image)  \n",
    "        image_ids.append(test_image_list[i])\n",
    "        total += 1\n",
    "        if total % 100 == 0:\n",
    "            print \".\",\n",
    "    print \"\\nProcesses {} rows.\".format(total)\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    images = images.reshape(images.shape[0], color_type, image_width, image_height)\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    return images, np.array(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Processes 79726 rows.\n",
      "(79726, 1, 224, 224)\n",
      "(79726,)\n"
     ]
    }
   ],
   "source": [
    "test_data, test_ids = load_test_images(test_images_dir)  \n",
    "print test_data.shape\n",
    "print test_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a deep CNN using Keras\n",
    "Starting with no pre-loaded weights though as we'll train this with our own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D  \n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, MaxPooling1D\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Custom Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_keras_model(num_classes, weights_path=None, w_regularizer = None, b_regularizer = None):\n",
    "    num_filters = 8      \n",
    "    num_pooling = 2\n",
    "    num_filters_2 = 8\n",
    "    filter_length = 3     \n",
    "    \n",
    "    # Create callback for history report\n",
    "    from keras.callbacks import Callback\n",
    "    class LossHistory(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "    \n",
    "    \n",
    "    #from keras.utils.dot_utils import Grapher\n",
    "    \n",
    "    model = Sequential()\n",
    "    #grapher = Grapher()\n",
    "\n",
    "    # Now create the NN architecture (version 1)\n",
    "    # Going with colour for now!!\n",
    "    model.add(Convolution2D(num_filters, filter_length, filter_length, border_mode=\"valid\", \n",
    "                        activation=\"relu\", \n",
    "                        W_regularizer = w_regularizer, b_regularizer = b_regularizer,\n",
    "                        input_shape=(color_type, image_width, image_height)))\n",
    "    \n",
    "    # Added\n",
    "    model.add(MaxPooling2D(pool_size=(num_pooling, num_pooling)))  \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(num_filters_2, filter_length, filter_length, \n",
    "                            W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(num_pooling, num_pooling)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, \n",
    "              W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, \n",
    "              W_regularizer = w_regularizer, b_regularizer = b_regularizer))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    if weights_path:\n",
    "        print \"Loading weights from {}\".format(weights_path)\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "\n",
    "    #model.summary()\n",
    "    #grapher.plot(model, 'nn_model.png')\n",
    "    \n",
    "    # TODO - Handle loading existing weights \n",
    "    \n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###VGG16 model\n",
    "From https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "Also see:\n",
    "http://blog.christianperone.com/2016/01/convolutional-hypercolumns-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg16(num_classes, weights_path=None):\n",
    "    \n",
    "    # Create callback for history report\n",
    "    from keras.callbacks import Callback\n",
    "    class LossHistory(Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(color_type, image_width, image_height)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        print \"Loading weights from {}\".format(weights_path)\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "    # Now replace the top layer with one for our own purposes\n",
    "    model.layers.pop()\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    #TODO - Rework model based on \n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which NN we are going to use, and whether to load weights or train ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graph_training_loss_history(losses):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(losses)\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('batch')\n",
    "    plt.title('training error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def get_log_loss_score(model, X_valid, y_valid):\n",
    "    predictions_valid = model.predict(X_valid, batch_size=128, verbose=1)\n",
    "    score = log_loss(y_valid, predictions_valid)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Configure the network - only our custom 'LeNet' model is available \n",
    "def compile_model(learning_rate=0.1, w_regularizer=None, b_regularizer=None):\n",
    "    if keras_model == 'custom':\n",
    "        model, LossHistory = custom_keras_model(num_classes, weights, w_regularizer, b_regularizer)\n",
    "        sgd = SGD(lr=learning_rate, decay=0, momentum=0, nesterov=False)\n",
    "        #sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    elif keras_model == 'vgg16':\n",
    "        model, LossHistory = vgg16(num_classes, weights)\n",
    "        sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # Now compile the model\n",
    "    model.compile(loss=loss_function, optimizer=sgd, metrics=['accuracy'])\n",
    "    return model, LossHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras_model, weights, train_model = 'custom', None, True\n",
    "#keras_model, weights, train_model = 'vgg16', None, False\n",
    "loss_function='categorical_crossentropy'\n",
    "from keras.regularizers import l1, l2\n",
    "w_regularizer = l2(0.1) # Default = None\n",
    "b_regularizer = l2(0.1) # Default = None\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_5 (Convolution2D)  (None, 8, 222, 222)   80          convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 8, 111, 111)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 8, 111, 111)   0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 8, 109, 109)   584         dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 8, 109, 109)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 8, 54, 54)     0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 8, 54, 54)     0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 23328)         0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           2986112     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 128)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 128)           0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            1290        dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 10)            0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2988066\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"994pt\" viewBox=\"0.00 0.00 229.68 994.00\" width=\"230pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 990)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-990 225.68,-990 225.68,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4963488400 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4963488400</title>\n",
       "<polygon fill=\"none\" points=\"0,-949.5 0,-985.5 221.68,-985.5 221.68,-949.5 0,-949.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-963.3\">convolution2d_input_3 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 4963489168 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4963489168</title>\n",
       "<polygon fill=\"none\" points=\"5.42773,-876.5 5.42773,-912.5 216.252,-912.5 216.252,-876.5 5.42773,-876.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-890.3\">convolution2d_5 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 4963488400&#45;&gt;4963489168 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4963488400-&gt;4963489168</title>\n",
       "<path d=\"M110.84,-949.313C110.84,-941.289 110.84,-931.547 110.84,-922.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-922.529 110.84,-912.529 107.34,-922.529 114.34,-922.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4391530896 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4391530896</title>\n",
       "<polygon fill=\"none\" points=\"5.81738,-803.5 5.81738,-839.5 215.862,-839.5 215.862,-803.5 5.81738,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-817.3\">maxpooling2d_5 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 4963489168&#45;&gt;4391530896 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4963489168-&gt;4391530896</title>\n",
       "<path d=\"M110.84,-876.313C110.84,-868.289 110.84,-858.547 110.84,-849.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-849.529 110.84,-839.529 107.34,-849.529 114.34,-849.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4391531344 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4391531344</title>\n",
       "<polygon fill=\"none\" points=\"44.3208,-730.5 44.3208,-766.5 177.359,-766.5 177.359,-730.5 44.3208,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-744.3\">dropout_7 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4391530896&#45;&gt;4391531344 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4391530896-&gt;4391531344</title>\n",
       "<path d=\"M110.84,-803.313C110.84,-795.289 110.84,-785.547 110.84,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-776.529 110.84,-766.529 107.34,-776.529 114.34,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4391287760 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4391287760</title>\n",
       "<polygon fill=\"none\" points=\"5.42773,-657.5 5.42773,-693.5 216.252,-693.5 216.252,-657.5 5.42773,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-671.3\">convolution2d_6 (Convolution2D)</text>\n",
       "</g>\n",
       "<!-- 4391531344&#45;&gt;4391287760 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4391531344-&gt;4391287760</title>\n",
       "<path d=\"M110.84,-730.313C110.84,-722.289 110.84,-712.547 110.84,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-703.529 110.84,-693.529 107.34,-703.529 114.34,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4391168784 -->\n",
       "<g class=\"node\" id=\"node6\"><title>4391168784</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-584.5 32.2793,-620.5 189.4,-620.5 189.4,-584.5 32.2793,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-598.3\">activation_7 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4391287760&#45;&gt;4391168784 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4391287760-&gt;4391168784</title>\n",
       "<path d=\"M110.84,-657.313C110.84,-649.289 110.84,-639.547 110.84,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-630.529 110.84,-620.529 107.34,-630.529 114.34,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4963007888 -->\n",
       "<g class=\"node\" id=\"node7\"><title>4963007888</title>\n",
       "<polygon fill=\"none\" points=\"5.81738,-511.5 5.81738,-547.5 215.862,-547.5 215.862,-511.5 5.81738,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-525.3\">maxpooling2d_6 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 4391168784&#45;&gt;4963007888 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>4391168784-&gt;4963007888</title>\n",
       "<path d=\"M110.84,-584.313C110.84,-576.289 110.84,-566.547 110.84,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-557.529 110.84,-547.529 107.34,-557.529 114.34,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4391053264 -->\n",
       "<g class=\"node\" id=\"node8\"><title>4391053264</title>\n",
       "<polygon fill=\"none\" points=\"44.3208,-438.5 44.3208,-474.5 177.359,-474.5 177.359,-438.5 44.3208,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-452.3\">dropout_8 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4963007888&#45;&gt;4391053264 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>4963007888-&gt;4391053264</title>\n",
       "<path d=\"M110.84,-511.313C110.84,-503.289 110.84,-493.547 110.84,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-484.529 110.84,-474.529 107.34,-484.529 114.34,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4391254288 -->\n",
       "<g class=\"node\" id=\"node9\"><title>4391254288</title>\n",
       "<polygon fill=\"none\" points=\"52.4897,-365.5 52.4897,-401.5 169.19,-401.5 169.19,-365.5 52.4897,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-379.3\">flatten_3 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 4391053264&#45;&gt;4391254288 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>4391053264-&gt;4391254288</title>\n",
       "<path d=\"M110.84,-438.313C110.84,-430.289 110.84,-420.547 110.84,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-411.529 110.84,-401.529 107.34,-411.529 114.34,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4503994896 -->\n",
       "<g class=\"node\" id=\"node10\"><title>4503994896</title>\n",
       "<polygon fill=\"none\" points=\"55.9966,-292.5 55.9966,-328.5 165.683,-328.5 165.683,-292.5 55.9966,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-306.3\">dense_5 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4391254288&#45;&gt;4503994896 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>4391254288-&gt;4503994896</title>\n",
       "<path d=\"M110.84,-365.313C110.84,-357.289 110.84,-347.547 110.84,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-338.529 110.84,-328.529 107.34,-338.529 114.34,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4503996688 -->\n",
       "<g class=\"node\" id=\"node11\"><title>4503996688</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-219.5 32.2793,-255.5 189.4,-255.5 189.4,-219.5 32.2793,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-233.3\">activation_8 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4503994896&#45;&gt;4503996688 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>4503994896-&gt;4503996688</title>\n",
       "<path d=\"M110.84,-292.313C110.84,-284.289 110.84,-274.547 110.84,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-265.529 110.84,-255.529 107.34,-265.529 114.34,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4504032720 -->\n",
       "<g class=\"node\" id=\"node12\"><title>4504032720</title>\n",
       "<polygon fill=\"none\" points=\"44.3208,-146.5 44.3208,-182.5 177.359,-182.5 177.359,-146.5 44.3208,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-160.3\">dropout_9 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 4503996688&#45;&gt;4504032720 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>4503996688-&gt;4504032720</title>\n",
       "<path d=\"M110.84,-219.313C110.84,-211.289 110.84,-201.547 110.84,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-192.529 110.84,-182.529 107.34,-192.529 114.34,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4504093136 -->\n",
       "<g class=\"node\" id=\"node13\"><title>4504093136</title>\n",
       "<polygon fill=\"none\" points=\"55.9966,-73.5 55.9966,-109.5 165.683,-109.5 165.683,-73.5 55.9966,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-87.3\">dense_6 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4504032720&#45;&gt;4504093136 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>4504032720-&gt;4504093136</title>\n",
       "<path d=\"M110.84,-146.313C110.84,-138.289 110.84,-128.547 110.84,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-119.529 110.84,-109.529 107.34,-119.529 114.34,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4504094928 -->\n",
       "<g class=\"node\" id=\"node14\"><title>4504094928</title>\n",
       "<polygon fill=\"none\" points=\"32.2793,-0.5 32.2793,-36.5 189.4,-36.5 189.4,-0.5 32.2793,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.84\" y=\"-14.3\">activation_9 (Activation)</text>\n",
       "</g>\n",
       "<!-- 4504093136&#45;&gt;4504094928 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>4504093136-&gt;4504094928</title>\n",
       "<path d=\"M110.84,-73.3129C110.84,-65.2895 110.84,-55.5475 110.84,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"114.34,-46.5288 110.84,-36.5288 107.34,-46.5289 114.34,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model so we can get a view of what it looks like\n",
    "# Note we'll do this in each training iteration later, but this'll keep the output tidy!\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "model, LossHistory = compile_model()\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "Train and use validation data to see if we're training effectively!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************\n",
      "\n",
      "Starting training iteration 1 with learning rate 0.003\n",
      "\n",
      "Train on 20975 samples, validate on 1449 samples\n",
      "Epoch 1/20\n",
      "20975/20975 [==============================] - 401s - loss: 7.1907 - acc: 0.1158 - val_loss: 2.2917 - val_acc: 0.1511\n",
      "Epoch 2/20\n",
      "20975/20975 [==============================] - 398s - loss: 4.4993 - acc: 0.1481 - val_loss: 2.2834 - val_acc: 0.1801\n",
      "Epoch 3/20\n",
      "20975/20975 [==============================] - 399s - loss: 3.2737 - acc: 0.1698 - val_loss: 2.2718 - val_acc: 0.2153\n",
      "Epoch 4/20\n",
      "20975/20975 [==============================] - 394s - loss: 2.7061 - acc: 0.2033 - val_loss: 2.2569 - val_acc: 0.2581\n",
      "Epoch 5/20\n",
      "20975/20975 [==============================] - 399s - loss: 2.4332 - acc: 0.2274 - val_loss: 2.2330 - val_acc: 0.3223\n",
      "Epoch 6/20\n",
      "20975/20975 [==============================] - 392s - loss: 2.2839 - acc: 0.2523 - val_loss: 2.1989 - val_acc: 0.2802\n",
      "Epoch 7/20\n",
      "20975/20975 [==============================] - 400s - loss: 2.1640 - acc: 0.2802 - val_loss: 2.1712 - val_acc: 0.3430\n",
      "Epoch 8/20\n",
      "20975/20975 [==============================] - 396s - loss: 2.0383 - acc: 0.3191 - val_loss: 2.1328 - val_acc: 0.4106\n",
      "Epoch 9/20\n",
      "20975/20975 [==============================] - 396s - loss: 1.9233 - acc: 0.3500 - val_loss: 2.0941 - val_acc: 0.3485\n",
      "Epoch 10/20\n",
      "20975/20975 [==============================] - 398s - loss: 1.8252 - acc: 0.3875 - val_loss: 2.0618 - val_acc: 0.4555\n",
      "Epoch 11/20\n",
      "20975/20975 [==============================] - 398s - loss: 1.7199 - acc: 0.4250 - val_loss: 2.0713 - val_acc: 0.4127\n",
      "Epoch 12/20\n",
      "20975/20975 [==============================] - 397s - loss: 1.6391 - acc: 0.4534 - val_loss: 2.0104 - val_acc: 0.4168\n",
      "Epoch 13/20\n",
      "20975/20975 [==============================] - 397s - loss: 1.5511 - acc: 0.4906 - val_loss: 1.9508 - val_acc: 0.5003\n",
      "Epoch 14/20\n",
      "20975/20975 [==============================] - 397s - loss: 1.4693 - acc: 0.5223 - val_loss: 2.1011 - val_acc: 0.4603\n",
      "Epoch 15/20\n",
      "20975/20975 [==============================] - 397s - loss: 1.4012 - acc: 0.5463 - val_loss: 1.9411 - val_acc: 0.4776\n",
      "Epoch 16/20\n",
      "20975/20975 [==============================] - 401s - loss: 1.3281 - acc: 0.5745 - val_loss: 1.9868 - val_acc: 0.5079\n",
      "Epoch 17/20\n",
      "20975/20975 [==============================] - 405s - loss: 1.2574 - acc: 0.5997 - val_loss: 2.0484 - val_acc: 0.4796\n",
      "Epoch 18/20\n",
      "20975/20975 [==============================] - 408s - loss: 1.2036 - acc: 0.6247 - val_loss: 1.9803 - val_acc: 0.5424\n",
      "Epoch 19/20\n",
      "20975/20975 [==============================] - 403s - loss: 1.1562 - acc: 0.6369 - val_loss: 1.9802 - val_acc: 0.5349\n",
      "Epoch 20/20\n",
      "20975/20975 [==============================] - 394s - loss: 1.1143 - acc: 0.6524 - val_loss: 2.0758 - val_acc: 0.4569\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAADhCAYAAAAjxHmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICIiOf4fvmlQ0U1v4k4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133f82e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 20 #10\n",
    "learning_rate = [0.003] # [0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "\n",
    "for i in range(len(learning_rate)):\n",
    "    learningrate = learning_rate[i]\n",
    "    print \"\\n**********************************\"\n",
    "    print \"\\nStarting training iteration {} with learning rate {}\\n\".format(i+1, learningrate)\n",
    "    model, LossHistory = compile_model(learningrate, w_regularizer, b_regularizer)\n",
    "    history = LossHistory()\n",
    "    #model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=num_epochs,\n",
    "    #          verbose=1, validation_data=(X_valid, y_valid), shuffle=True,\n",
    "    #          callbacks=[history]) \n",
    "    hist = model.fit(X_train, y_train,            \n",
    "              batch_size=batch_size, \n",
    "              nb_epoch=num_epochs,\n",
    "              verbose=1,\n",
    "              #validation_split = 0.10, \n",
    "              shuffle=True,\n",
    "              validation_data=(X_valid, y_valid), \n",
    "              callbacks=[history])\n",
    "    # validation_data=(X_train[validation_list], y_train[validation_list]),\n",
    "    graph_training_loss_history(history.losses)\n",
    "    model.save_weights('./model/saved_weights_lr_' + str(learningrate)+'.h5')\n",
    "    #print('Score log_loss: ', get_log_loss_score(model, X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./model/saved_weights_' + keras_model + '_' + str(batch_size) + '_' + str(num_epochs) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc', 'loss', 'val_acc', 'val_loss']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEZCAYAAACXRVJOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGMMAP8PW93oLQ+GJo8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e7c36d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEZCAYAAAB2AoVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nULIXEUkB/x/kbrFwvUnzbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e881750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load the best weights from above\n",
    "In this test, a learning rate of 0.003 worked best, so load this weights file now ready for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('model/saved_weights_lr_0.003.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726/79726 [==============================] - 643s   \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data, batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79726, 10)\n"
     ]
    }
   ],
   "source": [
    "print predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.24912384e-04   1.72316752e-04   1.39586888e-02   1.74821631e-04\n",
      "   2.34024905e-04   9.75843906e-01   4.18665214e-03   2.89488910e-03\n",
      "   1.23334862e-03   6.76434778e-04]\n"
     ]
    }
   ],
   "source": [
    "print predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def create_submission(predictions, test_ids, test_info):\n",
    "    result = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result.loc[:, 'img'] = pd.Series(test_ids, index=result.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('submission'):\n",
    "        os.mkdir('submission')\n",
    "    suffix = test_info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('submission', 'submission_' + suffix + '.csv')\n",
    "    result.to_csv(sub_file, index=False)\n",
    "\n",
    "#+ str(score) \\\n",
    "test_info = 'loss_' \\\n",
    "                + '_h_' + str(image_height) \\\n",
    "                + '_w_' + str(image_width) \\\n",
    "                + '_ep_' + str(num_epochs)\n",
    "create_submission(predictions, test_ids, test_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Use Validation Data to Understand Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1449/1449 [==============================] - 11s    \n"
     ]
    }
   ],
   "source": [
    "vpredictions = model.predict(X_valid, batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.34547055e-01   1.19403540e-03   6.94825721e-05 ...,   1.67880553e-05\n",
      "    2.75434810e-03   2.97627091e-01]\n",
      " [  6.44880891e-01   2.97865132e-03   1.76933841e-04 ...,   4.80634335e-05\n",
      "    4.85972641e-03   2.77138889e-01]\n",
      " [  6.72597170e-01   7.39449495e-03   5.47737465e-04 ...,   6.45421023e-05\n",
      "    7.59685086e-03   2.28580207e-01]\n",
      " ..., \n",
      " [  2.86424279e-01   4.95072268e-02   1.00864366e-01 ...,   5.73345087e-03\n",
      "    7.60333985e-02   1.35453016e-01]\n",
      " [  2.46058658e-01   6.12950511e-02   1.21379420e-01 ...,   9.75283794e-03\n",
      "    7.48897791e-02   1.62880376e-01]\n",
      " [  2.97412217e-01   6.38453737e-02   9.54688489e-02 ...,   7.19732745e-03\n",
      "    6.64712489e-02   1.58114105e-01]]\n"
     ]
    }
   ],
   "source": [
    "print vpredictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probability_to_binary(predictions):\n",
    "    results = []\n",
    "    for pred in predictions:\n",
    "        idx = np.argmax(pred)\n",
    "        result = np.zeros(len(pred))\n",
    "        result[idx] = 1\n",
    "        results.append(result)\n",
    "    return results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Failed!: Class 0, 9 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 3 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 9 predicted\n",
      "Failed!: Class 1, 9 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 1, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 9 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 9 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 9 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 0 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Failed!: Class 2, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Failed!: Class 4, 9 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 0 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 3 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 9 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 3 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 1 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 1 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 6, 0 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 9 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 1 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 7, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 3 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 9 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Failed!: Class 0, 3 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Failed!: Class 0, 1 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Success: Class 0, 0 predicted\n",
      "Failed!: Class 1, 2 predicted\n",
      "Failed!: Class 1, 2 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Failed!: Class 1, 2 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Failed!: Class 1, 2 predicted\n",
      "Failed!: Class 1, 2 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 1, 1 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 2, 2 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Failed!: Class 3, 0 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 3, 3 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Failed!: Class 4, 3 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 4, 4 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 2 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 1 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 0 predicted\n",
      "Success: Class 5, 5 predicted\n",
      "Failed!: Class 5, 3 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Failed!: Class 6, 3 predicted\n",
      "Failed!: Class 6, 8 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Success: Class 6, 6 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 6, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 6 predicted\n",
      "Failed!: Class 7, 6 predicted\n",
      "Failed!: Class 7, 6 predicted\n",
      "Failed!: Class 7, 6 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 6 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 6 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 6 predicted\n",
      "Success: Class 7, 7 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Success: Class 7, 7 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Success: Class 7, 7 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Success: Class 7, 7 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Success: Class 7, 7 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Success: Class 7, 7 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 8 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Failed!: Class 7, 2 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 6 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 6 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Failed!: Class 8, 0 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Failed!: Class 8, 1 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Success: Class 8, 8 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Success: Class 9, 9 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n",
      "Failed!: Class 9, 0 predicted\n"
     ]
    }
   ],
   "source": [
    "y_predictions = probability_to_binary(vpredictions)\n",
    "\n",
    "\n",
    "for yclass, ypredict in zip(y_valid, y_predictions):\n",
    "    if np.argmax(yclass) == np.argmax(ypredict):\n",
    "        print \"Success: Class {}, {} predicted\".format(np.argmax(yclass), np.argmax(ypredict))\n",
    "    else:\n",
    "        print \"Failed!: Class {}, {} predicted\".format(np.argmax(yclass), np.argmax(ypredict))\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional NN metrics, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the weights, biases, etc. for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W_constraint': None, 'b_constraint': None, 'name': 'convolution2d_3', 'activity_regularizer': None, 'trainable': True, 'dim_ordering': 'th', 'nb_col': 3, 'subsample': (1, 1), 'init': 'glorot_uniform', 'bias': True, 'nb_filter': 8, 'activation': 'relu', 'input_dtype': 'float32', 'batch_input_shape': (None, 1, 224, 224), 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'nb_row': 3, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'border_mode': 'valid'}\n",
      "[array([[[[ 0.15798764, -0.26940349,  0.24715555],\n",
      "         [ 0.13878237, -0.12262621, -0.23275992],\n",
      "         [ 0.16588999,  0.11729886, -0.19583708]]],\n",
      "\n",
      "\n",
      "       [[[-0.73994195, -0.52082288, -0.4964388 ],\n",
      "         [-0.60405433, -0.07172391,  0.60624444],\n",
      "         [ 0.45547041,  0.93813646,  0.81139374]]],\n",
      "\n",
      "\n",
      "       [[[-1.68558943, -1.23065007, -0.18032779],\n",
      "         [-0.14056876,  0.58800739,  0.65498114],\n",
      "         [ 0.34169093,  0.83168703,  0.9269051 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.43811062,  0.49014685, -0.23297071],\n",
      "         [ 0.34388128,  0.13366939, -0.15214261],\n",
      "         [ 0.2354643 , -0.08434661, -0.26753783]]],\n",
      "\n",
      "\n",
      "       [[[ 0.25292528,  0.12966618,  0.18178554],\n",
      "         [ 0.22634226,  0.04379258,  0.26711866],\n",
      "         [-0.34504536,  0.00715635,  0.23054361]]],\n",
      "\n",
      "\n",
      "       [[[ 0.17779198,  0.13328673, -0.06198414],\n",
      "         [-0.04374534,  0.24861899, -0.25968838],\n",
      "         [ 0.2800312 , -0.18131828, -0.1836888 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.42240021,  0.17614986,  0.27706149],\n",
      "         [-0.09610502, -0.08328727, -0.02854088],\n",
      "         [-0.02105968,  0.40895942,  0.0558939 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.03853405,  0.36999056,  0.36529747],\n",
      "         [-0.11962295,  0.07843321,  0.29465654],\n",
      "         [ 0.17400372,  0.26012865, -0.21401981]]]], dtype=float32), array([-0.03621067, -0.20189984, -0.27487698, -0.23507003, -0.31254193,\n",
      "       -0.05420746, -0.1038422 , -0.36736473], dtype=float32)]\n",
      "{'name': 'maxpooling2d_3', 'trainable': True, 'dim_ordering': 'th', 'pool_size': (2, 2), 'strides': (2, 2), 'border_mode': 'valid'}\n",
      "[]\n",
      "{'p': 0.25, 'trainable': True, 'name': 'dropout_4'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'convolution2d_4', 'activity_regularizer': None, 'trainable': True, 'dim_ordering': 'th', 'nb_col': 3, 'subsample': (1, 1), 'init': 'glorot_uniform', 'bias': True, 'nb_filter': 8, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'nb_row': 3, 'activation': 'linear', 'border_mode': 'valid'}\n",
      "[array([[[[ -1.34026662e-01,   8.07377994e-02,  -6.46129847e-02],\n",
      "         [  3.00681740e-02,   1.36504382e-01,  -6.15251511e-02],\n",
      "         [  1.17450215e-01,   4.95707430e-02,   1.02221310e-01]],\n",
      "\n",
      "        [[  5.45655638e-02,   6.99056908e-02,   2.25728944e-01],\n",
      "         [  2.80917704e-01,   3.00262094e-01,   3.97402525e-01],\n",
      "         [  4.27625775e-01,   3.94146234e-01,   2.36574650e-01]],\n",
      "\n",
      "        [[ -1.30582318e-01,   1.37641340e-01,  -3.11150774e-03],\n",
      "         [  3.04710627e-01,   4.22864735e-01,   3.61683100e-01],\n",
      "         [  2.16936961e-01,   7.03835547e-01,   3.48441511e-01]],\n",
      "\n",
      "        [[ -5.06224670e-02,  -6.51089475e-02,   9.91496630e-03],\n",
      "         [ -1.53457731e-01,  -1.50078461e-01,  -1.82722151e-01],\n",
      "         [ -1.12079009e-01,  -1.86909791e-02,   2.29677692e-01]],\n",
      "\n",
      "        [[ -2.55102217e-01,  -6.55690208e-02,  -1.53144613e-01],\n",
      "         [ -1.04985267e-01,  -1.82755385e-02,  -1.27843529e-01],\n",
      "         [  1.78468749e-01,   3.64169814e-02,   1.97013631e-01]],\n",
      "\n",
      "        [[  1.18125446e-01,   3.24146077e-02,  -1.88466311e-01],\n",
      "         [  1.65684819e-01,  -1.52128249e-01,   6.87289834e-02],\n",
      "         [ -1.59715906e-01,  -1.62766337e-01,   3.23500186e-02]],\n",
      "\n",
      "        [[ -5.68162389e-02,  -3.26405019e-02,   1.34382665e-01],\n",
      "         [  1.97662696e-01,   1.95842423e-02,   2.38227904e-01],\n",
      "         [ -7.16538057e-02,  -6.42715394e-03,   2.03806192e-01]],\n",
      "\n",
      "        [[ -2.55695254e-01,  -1.01114467e-01,   1.02877095e-01],\n",
      "         [ -1.38200656e-01,   1.57127261e-01,  -7.51647204e-02],\n",
      "         [ -1.17945140e-02,   1.25966847e-01,   3.86073738e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -1.50935337e-01,  -2.58355513e-02,  -7.69074708e-02],\n",
      "         [  1.70784011e-01,   1.15530536e-01,  -2.00084239e-01],\n",
      "         [  3.54961939e-02,  -1.54196262e-01,   1.02498285e-01]],\n",
      "\n",
      "        [[ -1.71363413e-01,  -7.20096454e-02,   4.22327705e-02],\n",
      "         [ -1.27533423e-02,  -8.46121982e-02,   6.57348707e-02],\n",
      "         [ -2.03400686e-01,   5.65569885e-02,  -1.15443267e-01]],\n",
      "\n",
      "        [[ -6.24200031e-02,  -1.95878670e-02,  -1.56695276e-01],\n",
      "         [ -3.55933746e-03,   4.04093899e-02,  -1.90870002e-01],\n",
      "         [  4.67601344e-02,  -2.58296765e-02,  -4.08654362e-02]],\n",
      "\n",
      "        [[  3.65570895e-02,  -1.37878269e-01,   1.58862285e-02],\n",
      "         [ -1.32701933e-01,  -1.94973558e-01,  -4.47540767e-02],\n",
      "         [ -1.09681875e-01,  -1.00832032e-02,  -1.89619735e-01]],\n",
      "\n",
      "        [[  9.75520760e-02,  -5.13398973e-03,  -1.50441587e-01],\n",
      "         [ -7.41016939e-02,   2.23911479e-02,  -4.85601798e-02],\n",
      "         [ -1.30828306e-01,  -1.24013998e-01,   5.60702384e-02]],\n",
      "\n",
      "        [[  1.10940106e-01,  -1.72561228e-01,  -1.54427975e-01],\n",
      "         [ -6.00919574e-02,  -1.44397080e-01,   1.70612693e-01],\n",
      "         [ -3.39599177e-02,   1.52664900e-01,  -1.27477631e-01]],\n",
      "\n",
      "        [[  7.70184100e-02,  -8.34728554e-02,   8.83945674e-02],\n",
      "         [ -4.76690084e-02,   2.77167261e-02,  -3.22595648e-02],\n",
      "         [ -1.21153958e-01,   3.65889072e-02,   1.60985246e-01]],\n",
      "\n",
      "        [[ -8.21217746e-02,  -1.21021777e-01,   1.61140725e-01],\n",
      "         [  5.27676307e-02,  -6.47312477e-02,  -1.72004938e-01],\n",
      "         [  6.92910627e-02,  -8.20485130e-02,  -6.24316297e-02]]],\n",
      "\n",
      "\n",
      "       [[[  1.40374573e-02,   9.27775800e-02,  -1.34497494e-01],\n",
      "         [ -1.13285601e-01,   1.01350307e-01,  -1.09266132e-01],\n",
      "         [ -1.89159095e-01,   1.98934808e-01,   6.72081187e-02]],\n",
      "\n",
      "        [[  3.27511020e-02,   1.17634967e-01,  -1.27269715e-01],\n",
      "         [  1.52646720e-01,  -1.52425200e-01,   2.25905970e-01],\n",
      "         [  1.64977297e-01,   1.00876026e-01,   2.32137501e-01]],\n",
      "\n",
      "        [[ -1.89209357e-01,   6.58470020e-02,   1.23132303e-01],\n",
      "         [  1.16078347e-01,  -7.57754296e-02,   1.26088351e-01],\n",
      "         [ -2.59809010e-02,  -1.47030175e-01,  -1.33494912e-02]],\n",
      "\n",
      "        [[ -1.80959672e-01,   6.84457645e-02,   4.38374430e-02],\n",
      "         [ -3.80881988e-02,   1.80430397e-01,  -1.51213259e-01],\n",
      "         [ -8.61949101e-02,   6.80425379e-04,  -1.56776741e-01]],\n",
      "\n",
      "        [[ -1.44900247e-01,   7.61443526e-02,  -9.00308266e-02],\n",
      "         [ -1.79905757e-01,   9.18414369e-02,   2.06666104e-02],\n",
      "         [ -1.81725353e-01,  -2.81965174e-02,  -1.76461756e-01]],\n",
      "\n",
      "        [[ -9.68422815e-02,   1.94353789e-01,  -8.60045031e-02],\n",
      "         [  1.30025655e-01,   1.23418614e-01,  -1.69662833e-01],\n",
      "         [  7.54983425e-02,  -1.66469201e-01,   1.02248751e-01]],\n",
      "\n",
      "        [[ -1.56135216e-01,  -7.77975768e-02,   3.57889035e-03],\n",
      "         [ -1.13661572e-01,   2.00226456e-01,  -1.10816173e-01],\n",
      "         [ -1.56880707e-01,   9.26466882e-02,  -3.39139774e-02]],\n",
      "\n",
      "        [[  1.97939172e-01,   1.86556503e-02,   1.08044147e-01],\n",
      "         [  3.53233740e-02,  -2.83028632e-02,  -1.35943890e-01],\n",
      "         [  9.73007753e-02,  -1.10585660e-01,  -4.02854048e-02]]],\n",
      "\n",
      "\n",
      "       [[[  1.61055908e-01,   5.06385677e-02,   1.56299770e-01],\n",
      "         [ -7.59555995e-02,  -1.41047418e-01,   2.03572243e-01],\n",
      "         [ -1.94990680e-01,   3.86845209e-02,  -1.27528459e-01]],\n",
      "\n",
      "        [[ -1.32030740e-01,   1.32898644e-01,  -1.06576219e-01],\n",
      "         [  2.13226959e-01,   3.90804499e-01,   3.54597270e-01],\n",
      "         [  3.79311442e-01,   1.14088640e-01,   4.13883813e-02]],\n",
      "\n",
      "        [[  1.01797327e-01,  -1.87749460e-01,  -1.65094525e-01],\n",
      "         [  7.01736435e-02,   2.65763909e-01,  -2.16975954e-04],\n",
      "         [  4.37777042e-01,   6.18853569e-01,   5.47952414e-01]],\n",
      "\n",
      "        [[ -5.58604188e-02,  -1.71977356e-01,  -1.34098783e-01],\n",
      "         [ -4.43494506e-02,  -2.07404196e-01,   4.17653844e-02],\n",
      "         [  1.55338347e-01,   6.92547411e-02,   1.42531618e-02]],\n",
      "\n",
      "        [[ -9.98816043e-02,  -6.13243282e-02,   1.38340175e-01],\n",
      "         [  1.89429242e-02,  -1.98375389e-01,  -9.86144021e-02],\n",
      "         [ -1.65095404e-01,   4.34281789e-02,   7.87793174e-02]],\n",
      "\n",
      "        [[ -1.83712021e-01,   5.33900708e-02,   1.00747719e-01],\n",
      "         [  4.60998006e-02,  -1.23421304e-01,  -1.51205212e-01],\n",
      "         [  1.35776117e-01,  -8.79866034e-02,  -1.20796710e-01]],\n",
      "\n",
      "        [[ -1.35596409e-01,   1.99403465e-02,   1.60227403e-01],\n",
      "         [  1.03854900e-02,   6.37241527e-02,  -1.64147466e-01],\n",
      "         [  2.47638505e-02,   1.36844024e-01,   9.93079394e-02]],\n",
      "\n",
      "        [[ -1.71116292e-01,  -2.19195053e-01,   6.60874546e-02],\n",
      "         [ -1.60946846e-01,   2.94212606e-02,   1.12008587e-01],\n",
      "         [ -1.15028314e-01,   1.54836625e-01,   2.95663858e-03]]],\n",
      "\n",
      "\n",
      "       [[[  1.32362276e-01,   1.06569901e-01,   7.97002167e-02],\n",
      "         [ -1.68951914e-01,   1.94478199e-01,   7.18228519e-02],\n",
      "         [  4.56590541e-02,   2.06334949e-01,  -7.00459927e-02]],\n",
      "\n",
      "        [[ -2.06193589e-02,  -1.99306086e-01,   1.78816825e-01],\n",
      "         [  2.26207316e-01,   2.24750236e-01,   2.04740569e-01],\n",
      "         [  2.62301505e-01,   3.41759443e-01,  -1.69866495e-02]],\n",
      "\n",
      "        [[ -1.91719130e-01,  -3.45352590e-02,  -7.96410218e-02],\n",
      "         [  1.89501956e-01,   1.05843328e-01,  -8.51246715e-02],\n",
      "         [  2.36440822e-01,   2.31560394e-01,   3.27617496e-01]],\n",
      "\n",
      "        [[  1.41975388e-01,   1.12498410e-01,   1.84779242e-01],\n",
      "         [ -1.24334447e-01,  -1.62688106e-01,  -1.79894045e-01],\n",
      "         [ -1.22840635e-01,  -1.07849659e-02,  -3.98991741e-02]],\n",
      "\n",
      "        [[ -1.80419445e-01,   1.69514656e-01,   7.45791644e-02],\n",
      "         [ -1.86484791e-02,  -6.17312267e-03,  -2.02477083e-01],\n",
      "         [ -7.86445141e-02,   7.56457523e-02,   1.00104837e-02]],\n",
      "\n",
      "        [[  1.16489969e-01,  -1.43883631e-01,  -5.90328313e-02],\n",
      "         [ -7.20457658e-02,  -8.82556662e-02,   5.86984679e-02],\n",
      "         [ -6.20561801e-02,   5.90625033e-02,   1.20547479e-02]],\n",
      "\n",
      "        [[ -1.59494989e-02,  -8.07980821e-02,   1.59984678e-01],\n",
      "         [  2.48661116e-02,  -1.67835474e-01,   8.24318305e-02],\n",
      "         [  5.51037565e-02,   1.56942844e-01,   1.57367855e-01]],\n",
      "\n",
      "        [[  2.01399326e-02,   1.20875001e-01,   1.36484250e-01],\n",
      "         [ -2.17072591e-01,  -1.47154510e-01,  -1.16323180e-01],\n",
      "         [ -1.53657719e-01,   6.20089695e-02,  -2.05865037e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -1.84003681e-01,  -5.40607783e-04,   4.58348840e-02],\n",
      "         [ -7.97649473e-02,   8.76022726e-02,  -1.19890667e-01],\n",
      "         [  1.14465199e-01,  -7.97896758e-02,   1.50145730e-02]],\n",
      "\n",
      "        [[ -1.09362215e-01,   9.58002508e-02,   3.40551674e-01],\n",
      "         [  4.34592813e-01,   4.04127091e-01,   3.97708058e-01],\n",
      "         [  3.69624019e-01,   2.93917626e-01,  -1.12118974e-01]],\n",
      "\n",
      "        [[  2.41007522e-01,   2.15622522e-02,   4.54917341e-01],\n",
      "         [  1.02143042e-01,   7.24775910e-01,   3.35192710e-01],\n",
      "         [  3.65545750e-01,   4.55680519e-01,   1.28989786e-01]],\n",
      "\n",
      "        [[ -1.89654782e-01,   1.07701302e-01,   1.84709281e-01],\n",
      "         [ -1.94947466e-01,  -3.15780528e-02,   3.06993008e-01],\n",
      "         [ -9.39249098e-02,   2.53484219e-01,   3.95917147e-01]],\n",
      "\n",
      "        [[  2.98192296e-02,  -1.55619502e-01,  -1.14066020e-01],\n",
      "         [  2.30198190e-01,   1.64564271e-02,   1.57887310e-01],\n",
      "         [ -5.21433875e-02,  -2.90948451e-02,   2.84163896e-02]],\n",
      "\n",
      "        [[  1.74525589e-01,  -7.19886571e-02,   2.20898818e-02],\n",
      "         [ -1.79628029e-01,   1.20781720e-01,  -1.26591980e-01],\n",
      "         [ -1.36997283e-01,   5.86522818e-02,   1.34458095e-01]],\n",
      "\n",
      "        [[ -3.07309348e-02,  -1.73668727e-01,  -8.87565091e-02],\n",
      "         [  8.61211792e-02,   1.76628619e-01,   2.24475842e-02],\n",
      "         [ -1.33778617e-01,  -5.46995923e-03,  -1.77433297e-01]],\n",
      "\n",
      "        [[  4.59527224e-02,  -1.75031126e-01,  -3.60923335e-02],\n",
      "         [  1.37618929e-01,   3.70100401e-02,   2.19788775e-01],\n",
      "         [  2.32685998e-01,   7.00514838e-02,   1.10160969e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.13152973e-01,  -1.48993567e-01,   1.71904609e-01],\n",
      "         [  1.29477352e-01,   5.91579601e-02,   1.99532613e-01],\n",
      "         [ -5.23704141e-02,  -5.19743450e-02,   7.42700770e-02]],\n",
      "\n",
      "        [[  1.11034058e-01,   6.02700889e-01,   2.23956674e-01],\n",
      "         [  4.45736706e-01,   5.52993655e-01,   2.62173057e-01],\n",
      "         [ -7.91487843e-02,  -1.10755943e-01,  -5.54498024e-02]],\n",
      "\n",
      "        [[  1.07122526e-01,   7.45000184e-01,   4.83212471e-01],\n",
      "         [  7.42595255e-01,   8.16908181e-01,   5.58416069e-01],\n",
      "         [  2.77618259e-01,  -8.51246864e-02,  -4.05674949e-02]],\n",
      "\n",
      "        [[ -1.91775903e-01,  -2.29295850e-01,   2.92701781e-01],\n",
      "         [ -1.79982871e-01,   6.91771805e-02,   3.71467412e-01],\n",
      "         [ -1.30014002e-01,   1.74424142e-01,   1.62393317e-01]],\n",
      "\n",
      "        [[ -5.57390265e-02,   1.82630181e-01,   2.32023478e-01],\n",
      "         [  4.30145636e-02,   3.81959975e-01,   3.73330675e-02],\n",
      "         [  3.01161855e-02,   3.31593335e-01,   2.95552999e-01]],\n",
      "\n",
      "        [[ -1.13248013e-01,   1.17869243e-01,   2.21637830e-01],\n",
      "         [  9.59639102e-02,  -1.17925316e-01,  -6.37454242e-02],\n",
      "         [ -1.32373154e-01,   2.21415028e-01,   2.81448454e-01]],\n",
      "\n",
      "        [[  5.45282029e-02,  -9.47285444e-02,   2.05683902e-01],\n",
      "         [  2.20865399e-01,   2.05022886e-01,   2.08783031e-01],\n",
      "         [  1.78592175e-01,   4.87466976e-02,  -1.22287169e-01]],\n",
      "\n",
      "        [[  1.78463906e-01,  -8.04711506e-02,   2.25818045e-02],\n",
      "         [  4.59423028e-02,   2.60838777e-01,   6.25676140e-02],\n",
      "         [  9.10434648e-02,   3.70032221e-01,   2.46571660e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -1.89054571e-02,   3.80248576e-02,   1.76263183e-01],\n",
      "         [  5.83530478e-02,  -1.75634861e-01,   2.16807812e-01],\n",
      "         [  1.28080264e-01,  -1.19645678e-01,  -7.97937289e-02]],\n",
      "\n",
      "        [[  3.09628751e-02,   1.88108250e-01,   4.78402734e-01],\n",
      "         [  1.80991516e-01,   5.23348331e-01,   4.94021773e-01],\n",
      "         [ -4.51631732e-02,  -3.43138985e-02,   1.48954883e-01]],\n",
      "\n",
      "        [[  1.87484324e-01,   5.87890565e-01,   4.40616339e-01],\n",
      "         [  3.48017931e-01,   8.31371367e-01,   6.04181349e-01],\n",
      "         [  1.91464618e-01,   4.72599506e-01,  -3.52117643e-02]],\n",
      "\n",
      "        [[ -1.99863270e-01,  -1.57310486e-01,  -1.53482884e-01],\n",
      "         [ -9.24410522e-02,   1.42693624e-01,   3.26830178e-01],\n",
      "         [ -1.16118111e-01,  -3.06452857e-03,   4.72011894e-01]],\n",
      "\n",
      "        [[  7.36609027e-02,   3.51850353e-02,   2.80716997e-02],\n",
      "         [  7.02410191e-02,   1.53118417e-01,   3.34507555e-01],\n",
      "         [  1.64682642e-01,   1.80286631e-01,   4.37131941e-01]],\n",
      "\n",
      "        [[  1.05840258e-01,   1.34482875e-01,  -6.09815270e-02],\n",
      "         [ -1.80161342e-01,   1.03607751e-01,   2.74400622e-01],\n",
      "         [  9.69758853e-02,  -1.13175280e-01,   1.18873142e-01]],\n",
      "\n",
      "        [[  7.07676075e-03,   8.94438401e-02,  -3.84757221e-02],\n",
      "         [  1.30905015e-02,   1.62564263e-01,   1.24399915e-01],\n",
      "         [  1.56307817e-01,  -7.08310306e-02,  -7.95438960e-02]],\n",
      "\n",
      "        [[ -6.38224706e-02,  -8.22534487e-02,   1.87568530e-01],\n",
      "         [  2.24030409e-02,   2.40707353e-01,   2.09672228e-01],\n",
      "         [  4.35993485e-02,   4.55227584e-01,   3.01559776e-01]]]], dtype=float32), array([-0.07912011, -0.00214549,  0.00243343, -0.01269725, -0.03008677,\n",
      "       -0.22036546, -0.36188841, -0.32430181], dtype=float32)]\n",
      "{'activation': 'relu', 'trainable': True, 'name': 'activation_4'}\n",
      "[]\n",
      "{'name': 'maxpooling2d_4', 'trainable': True, 'dim_ordering': 'th', 'pool_size': (2, 2), 'strides': (2, 2), 'border_mode': 'valid'}\n",
      "[]\n",
      "{'p': 0.25, 'trainable': True, 'name': 'dropout_5'}\n",
      "[]\n",
      "{'trainable': True, 'name': 'flatten_2'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'dense_3', 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'activation': 'linear', 'input_dim': None, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'output_dim': 128}\n",
      "[array([[ 0.0121994 , -0.01540998,  0.00822915, ...,  0.00782138,\n",
      "         0.01296692,  0.01324063],\n",
      "       [-0.01087579,  0.00749833,  0.00028079, ..., -0.00603844,\n",
      "         0.00688236, -0.0011218 ],\n",
      "       [ 0.0018305 ,  0.0131845 ,  0.00889361, ...,  0.01216622,\n",
      "        -0.01818432,  0.01242627],\n",
      "       ..., \n",
      "       [ 0.00430395, -0.01503965, -0.0001346 , ..., -0.02233445,\n",
      "         0.01027245, -0.00204884],\n",
      "       [ 0.01497846,  0.00107222, -0.02133265, ..., -0.01487993,\n",
      "        -0.0089016 ,  0.01518229],\n",
      "       [ 0.00076261, -0.01590371,  0.00906142, ..., -0.02610006,\n",
      "        -0.00458856, -0.00711058]], dtype=float32), array([  1.19415554e-03,  -1.29050273e-03,   2.01417413e-03,\n",
      "         7.25443359e-04,  -6.37966616e-04,  -3.42484354e-03,\n",
      "         3.44413170e-03,  -8.99217092e-04,   4.98900423e-03,\n",
      "         6.16313657e-03,  -1.27729421e-04,   2.60804454e-03,\n",
      "        -4.58635762e-03,   3.61107232e-04,   1.85590971e-03,\n",
      "        -6.02681306e-04,   7.98315799e-04,  -1.21205393e-03,\n",
      "        -4.76757111e-03,  -2.06456240e-03,  -2.32479023e-03,\n",
      "        -3.52169760e-03,  -3.03543429e-03,   4.09463607e-03,\n",
      "        -9.86779225e-04,  -2.16885563e-03,  -1.59984594e-03,\n",
      "        -1.86112418e-03,  -5.67875453e-04,  -1.29355059e-03,\n",
      "        -3.09133972e-03,  -8.35817889e-04,   6.17426587e-03,\n",
      "        -1.77123642e-03,  -4.06761217e-04,   6.43647322e-03,\n",
      "        -1.33629376e-03,  -1.34110078e-03,  -1.72654074e-03,\n",
      "         2.19544396e-03,  -1.52935239e-03,   4.57469001e-03,\n",
      "        -7.48313731e-04,   4.33305791e-03,  -6.54535019e-04,\n",
      "        -2.87829316e-03,  -1.19811692e-03,  -1.00214616e-03,\n",
      "        -3.58305406e-04,  -3.15060397e-03,  -1.60349373e-04,\n",
      "         9.87968501e-03,  -1.74027984e-03,   1.02903675e-02,\n",
      "        -2.46593525e-04,   2.64535029e-03,  -8.71906290e-04,\n",
      "        -1.96757517e-03,   3.08088679e-03,  -3.19878967e-03,\n",
      "         6.33344334e-03,  -2.90519954e-03,   5.84115740e-03,\n",
      "        -4.31862049e-04,   4.01016441e-04,   1.62985409e-03,\n",
      "         9.69599409e-04,  -4.40254225e-04,  -1.87514629e-03,\n",
      "         1.34370953e-03,  -3.59619129e-03,  -6.11563795e-04,\n",
      "         2.06638151e-03,  -7.37769878e-04,   3.78458248e-03,\n",
      "         1.11610014e-02,  -2.09250674e-03,   4.51554637e-03,\n",
      "        -2.88349180e-03,  -6.76510623e-04,  -2.56313151e-03,\n",
      "         9.85370111e-03,  -3.75518599e-03,  -1.65990088e-03,\n",
      "         7.15484982e-03,  -3.70519672e-04,   9.61048249e-03,\n",
      "         3.91256704e-04,  -4.53513535e-03,   3.95835936e-03,\n",
      "        -1.93574221e-03,  -1.72964297e-03,   3.38897714e-03,\n",
      "        -8.31536134e-04,   1.00335444e-03,   3.07834079e-03,\n",
      "        -1.83910510e-04,   1.54887536e-03,   1.77319825e-03,\n",
      "        -3.51566734e-04,  -1.46711234e-03,   1.91903883e-03,\n",
      "         3.55987286e-05,   1.09715518e-02,   6.70436211e-03,\n",
      "         6.38626609e-03,  -1.25045842e-03,  -2.72706803e-03,\n",
      "         3.33341677e-03,  -3.85910575e-03,  -1.80140210e-04,\n",
      "         6.07809611e-03,  -1.37493131e-03,  -3.41562531e-03,\n",
      "         5.06167859e-03,   8.09618551e-03,   8.97100603e-04,\n",
      "        -3.08992877e-03,   5.38192515e-04,   6.46606553e-03,\n",
      "         5.63733396e-04,   5.35535766e-03,   6.89913053e-03,\n",
      "         9.82741639e-03,   2.67700339e-03,  -1.90477050e-03,\n",
      "         7.40936142e-04,   3.01471073e-03], dtype=float32)]\n",
      "{'activation': 'relu', 'trainable': True, 'name': 'activation_5'}\n",
      "[]\n",
      "{'p': 0.5, 'trainable': True, 'name': 'dropout_6'}\n",
      "[]\n",
      "{'W_constraint': None, 'b_constraint': None, 'name': 'dense_4', 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'activation': 'linear', 'input_dim': None, 'b_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'W_regularizer': {'l2': 0.10000000149011612, 'name': 'WeightRegularizer', 'l1': 0.0}, 'output_dim': 10}\n",
      "[array([[  1.36285694e-03,  -2.05046614e-03,  -1.74210360e-03, ...,\n",
      "          2.75083847e-04,   1.85915633e-04,  -2.47934647e-03],\n",
      "       [  2.47294120e-05,  -1.95314613e-04,  -6.85804480e-08, ...,\n",
      "          2.16943421e-03,  -1.23392697e-03,  -7.67025806e-04],\n",
      "       [ -2.60666665e-02,  -1.80092528e-02,  -8.77880678e-03, ...,\n",
      "         -1.10833272e-02,   5.24859950e-02,  -5.01799071e-03],\n",
      "       ..., \n",
      "       [ -1.23996083e-02,  -6.10462576e-03,  -1.33603672e-03, ...,\n",
      "         -1.04100420e-03,  -1.33132087e-02,   1.03215709e-01],\n",
      "       [  3.39915697e-03,  -2.23237779e-02,  -2.31061932e-02, ...,\n",
      "         -1.07022021e-02,   2.39834506e-02,   9.75845978e-02],\n",
      "       [ -1.61722880e-02,  -6.29401673e-03,  -9.33710486e-03, ...,\n",
      "         -5.86342486e-03,  -1.82745345e-02,  -4.17539757e-03]], dtype=float32), array([ 0.00467097, -0.00359396,  0.00172842, -0.00901112, -0.00462087,\n",
      "       -0.00676952,  0.00503731,  0.00017666,  0.01025872,  0.0021234 ], dtype=float32)]\n",
      "{'activation': 'softmax', 'trainable': True, 'name': 'activation_6'}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print layer.get_config()\n",
    "    print layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused / broken code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Visualise what the CNN has learnt\n",
    "Inspired by https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py and https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'convolution2d_39 '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-f3c6f9e3b7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'convolution2d_39 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlayer_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Number of filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'convolution2d_39 '"
     ]
    }
   ],
   "source": [
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'convolution2d_39 '\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_output = layer_dict[layer_name].output\n",
    "\n",
    "# Number of filters\n",
    "n = 8\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "imsave('stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
